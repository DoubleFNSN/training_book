{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/projects/exSEEK_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, argparse, sys, os, errno\n",
    "from functools import reduce\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,auc,precision_recall_curve,average_precision_score\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from bokeh.palettes import Category20c\n",
    "from ipywidgets import interact,interactive, FloatSlider,IntSlider, RadioButtons,Dropdown,Tab,Text\n",
    "np.random.seed(1234)\n",
    "import IPython\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load plotting functions\n",
    "embed pdf; std_plot; display dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup figure template\n",
    "figure_template_path = 'bin'\n",
    "if figure_template_path not in sys.path:\n",
    "    sys.path.append(figure_template_path)\n",
    "from importlib import reload\n",
    "import figure_template\n",
    "#force reload of the module\n",
    "reload(figure_template)\n",
    "from figure_template import display_dataframe, embed_pdf_figure, embed_pdf_pages,std_plot,legendhandle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrix manipulating using Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])   # Create a rank 1 array\n",
    "print(type(a))            # Prints \"<class 'numpy.ndarray'>\"\n",
    "print(a.shape)            # Prints \"(3,)\"\n",
    "print(a[0], a[1], a[2])   # Prints \"1 2 3\"\n",
    "a[0] = 5                  # Change an element of the array\n",
    "print(a)                  # Prints \"[5, 2, 3]\"\n",
    "\n",
    "b = np.array([[1,2,3],[4,5,6]])    # Create a rank 2 array\n",
    "print(b.shape)                     # Prints \"(2, 3)\"\n",
    "print(b[0, 0], b[0, 1], b[1, 0])   # Prints \"1 2 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,2))   # Create an array of all zeros\n",
    "print(a)              # Prints \"[[ 0.  0.]\n",
    "                      #          [ 0.  0.]]\"\n",
    "\n",
    "b = np.ones((1,2))    # Create an array of all ones\n",
    "print(b)              # Prints \"[[ 1.  1.]]\"\n",
    "\n",
    "c = np.full((2,2), 7)  # Create a constant array\n",
    "print(c)               # Prints \"[[ 7.  7.]\n",
    "                       #          [ 7.  7.]]\"\n",
    "\n",
    "d = np.eye(2)         # Create a 2x2 identity matrix\n",
    "print(d)              # Prints \"[[ 1.  0.]\n",
    "                      #          [ 0.  1.]]\"\n",
    "\n",
    "e = np.random.random((2,2))  # Create an array filled with random values\n",
    "print(e)                     # Might print \"[[ 0.91940167  0.08143941]\n",
    "                             #               [ 0.68744134  0.87236687]]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.eye(15),cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random(100).reshape(10,10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.random.random(100).reshape(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a full-zero vector of size 10 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros(10)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a null vector of size 10 but the fifth value which is 1 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros(10)\n",
    "Z[4] = 1\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a vector with values ranging from 10 to 49 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.arange(10,50)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse a vector (first element becomes last) (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.arange(50)\n",
    "print(Z)\n",
    "Z = Z[::-1]\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 3x3 matrix with values ranging from 0 to 8 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.arange(9).reshape(3,3)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find indices of non-zero elements from \\[1,2,0,0,4,0\\] (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = np.nonzero([1,2,0,0,4,0])\n",
    "print(nz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 3x3 identity matrix (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.eye(3)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 3x3x3 array with random values (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.random.random((3,3,3))\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 10x10 array with random values and find the minimum and maximum values (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.random.random((10,10))\n",
    "Zmin, Zmax = Z.min(), Z.max()\n",
    "print(Zmin, Zmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a random vector of size 30 and find the mean value (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.random.random(30)\n",
    "m = Z.mean()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Create a 2d array with 1 on the border and 0 inside (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.ones((10,10))\n",
    "Z[1:-1,1:-1] = 0\n",
    "print(Z)\n",
    "imshow(Z,cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to add a border (filled with 0's) around an existing array? (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.ones((5,5))\n",
    "Z = np.pad(Z, pad_width=1, mode='constant', constant_values=0)\n",
    "print(Z)\n",
    "imshow(Z,cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 5x5 matrix with values 1,2,3,4 just below the diagonal (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.diag(1+np.arange(4),k=-1)\n",
    "print(Z)\n",
    "imshow(Z,cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 8x8 matrix and fill it with a checkerboard pattern (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((8,8),dtype=int)\n",
    "Z[1::2,::2] = 1\n",
    "Z[::2,1::2] = 1\n",
    "print(Z)\n",
    "imshow(Z,cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. Normalize a 5x5 random matrix (★☆☆)\n",
    "$$\n",
    "Z^{'} = \\frac{Z-\\mu}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(6,3))\n",
    "Z = np.random.random((5,5))\n",
    "ax[0].imshow(Z,cmap=cm.gray_r)\n",
    "Z = (Z - np.mean (Z)) / (np.std (Z))\n",
    "ax[1].imshow(Z,cmap=cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiply a 5x3 matrix by a 3x2 matrix (real matrix product) (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ,b = np.tile(np.eye(2),(4,4)),np.tile(np.eye(2),(4,4))[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(a ,b)\n",
    "print(Z)\n",
    "\n",
    "# Alternative solution, in Python 3.5 and above\n",
    "Z = a @ b\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(6,3))\n",
    "ax[0].imshow(a,cmap=cm.gray_r)\n",
    "ax[1].imshow(b,cmap=cm.gray_r)\n",
    "ax[2].imshow(Z,cmap=cm.gray_r)                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given a 1D array, negate all elements which are between 3 and 8, in place. (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.arange(11)\n",
    "Z[(3 < Z) & (Z <= 8)] *= -1\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to round away from zero a float array ? (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Charles R Harris\n",
    "Z = np.random.uniform(-10,+10,10)\n",
    "print (Z)\n",
    "print (np.copysign(np.ceil(np.abs(Z)), Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to find common values between two arrays? (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = np.random.randint(0,10,10)\n",
    "Z2 = np.random.randint(0,10,10)\n",
    "print(Z1,Z2,np.intersect1d(Z1,Z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a 5x5 matrix with row values ranging from 0 to 4 (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((5,5))\n",
    "Z += np.arange(5)  # which is called broadcasting\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a random vector of size 10 and sort it (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.random.random(10)\n",
    "print(Z,Z.argsort())\n",
    "Z.sort()\n",
    "print(Z,Z.argsort())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create random vector of size 10 and replace the maximum value by 0 (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.random.random(10)\n",
    "Z[Z.argmax()] = 0\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA&t-SNE visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (principle component analysis)\n",
    "- 通过线性组合得到贡献最大的、可解释的变量(principle components)\n",
    "- 数据的降维和可视化\n",
    "\n",
    "[PCA](https://zhuanlan.zhihu.com/p/37777074)<br>\n",
    "[SVD](https://mp.weixin.qq.com/s/Dv51K8JETakIKe5dPBAPVg)<br>\n",
    "[Hinton理解的PCA](https://www.jianshu.com/p/76c64cd0b5ad)<br>\n",
    "[PCA和SVD的区别与联系](https://blog.csdn.net/wangjian1204/article/details/50642732)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA的主要思想是将n维特征映射到k维上，这k维是新的彼此正交的特征，也被称为主成分。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身密切相关。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴。\n",
    "\n",
    "我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴，相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。\n",
    "\n",
    "**如何得到这些包含最大差异性的主成分方向？**\n",
    "\n",
    "通过计算数据矩阵的协方差矩阵，然后得到协方差矩阵的特征值特征向量，选择特征值最大(即方差最大)的k个特征所对应的特征向量组成的矩阵。这样就可以将数据矩阵转换到新的空间当中，实现数据特征的降维。<br>由于得到协方差矩阵的特征值特征向量有两种方法：特征值分解协方差矩阵、奇异值分解协方差矩阵，所以PCA算法有两种实现方法：基于特征值分解协方差矩阵实现PCA算法、基于SVD分解协方差矩阵实现PCA算法。\n",
    "\n",
    "**为什么要用协方差矩阵？为什么要对协方差矩阵做特征值分解？**\n",
    "\n",
    "$$\n",
    "\\text{均值： }\\overline { x } = \\frac { 1 } { n } \\sum _ { i = 1 } ^ { N } x _ { i }\\\\\n",
    "\\text{方差： }S ^ { 2 } = \\frac { 1 } { n - 1 } \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - \\overline { x } \\right) ^ { 2 }\\\\\n",
    "\\text{协方差： }\\begin{aligned} \\operatorname { Cov } ( X , Y ) & = E [ ( X - E ( X ) ) ( Y - E ( Y ) ) ] \\\\ & = \\frac { 1 } { n - 1 } \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - \\overline { x } \\right) \\left( y _ { i } - \\overline { y } \\right) \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,2,figsize=(10,5))\n",
    "corr_mat= np.array([[1.0, 0.6, 0.3],\n",
    "                    [0.6, 1.0, 0.5],\n",
    "                    [0.3, 0.5, 1.0],\n",
    "                   [0.5, 0.1, 1.0]])\n",
    "ax[0].imshow(corr_mat,cmap=cm.binary_r)\n",
    "ax[1].imshow(np.cov(corr_mat),cmap=cm.binary_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(corr_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**协方差矩阵表征了变量自身的“能量”/“信息”和彼此的关联性**\n",
    "假设样本中某个主要的维度A能代表原始数据，是“我们真正想看到的东西”，它本身含有的“能量”(即该维度的方差)，本来应该是很大的，但由于它与其他维度有千丝万缕的相关性，受到这些个相关维度的干扰，它的能量被削弱了，我们就希望通过PCA处理后，使维度A与其他维度的相关性尽可能减弱，进而恢复维度A应有的能量，让我们“看的更清楚”。\n",
    "\n",
    "最直观的思路就是将协方差矩阵只保留对角线上的元素，将其他元素变成零，在矩阵变换中这种操作被称为矩阵的对角化，方法包括特征值分解和奇异值分解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA算法推导\n",
    "\n",
    "$$\n",
    "X = \\left( \\begin{array} { c c c c c } { - 1 } & { - 1 } & { 0 } & { 2 } & { 0 } \\\\ { - 2 } & { 0 } & { 0 } & { 1 } & { 1 } \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "以X为例，我们用PCA方法将这两行数据降到一行。\n",
    "\n",
    "- 去平均值(即去中心化)，即每一位特征减去各自的平均值\n",
    "- 算协方差矩阵 $\\frac{1}{n} XX^T $\n",
    "- 用特征值分解方法求协方差矩阵$\\frac{1}{n}XX^T$ 的特征值与特征向量\n",
    "- 对特征值从大到小排序，选择其中最大的k个。然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P\n",
    "- 将数据转换到k个特征向量构建的新空间中，即Y=PX\n",
    "\n",
    "$$\n",
    "C = \\frac { 1 } { 5 } \\left( \\begin{array} { c c c c c } { - 1 } & { - 1 } & { 0 } & { 2 } & { 0 } \\\\ { - 2 } & { 0 } & { 0 } & { 1 } & { 1 } \\end{array} \\right) \\left( \\begin{array} { c c } { - 1 } & { - 2 } \\\\ { - 1 } & { 0 } \\\\ { 0 } & { 0 } \\\\ { 2 } & { 1 } \\\\ { 0 } & { 1 } \\end{array} \\right) = \\left( \\begin{array} { c c } { \\frac { 6 } { 5 } } & { \\frac { 4 } { 5 } } \\\\ { \\frac { 4 } { 5 } } & { \\frac { 6 } { 5 } } \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "求解后的特征值为：\n",
    "$$\n",
    "\\lambda _ { 1 } = 2 , \\quad \\lambda _ { 2 } = \\frac { 2 } { 5 }\n",
    "$$\n",
    "对应的特征向量为：\n",
    "$$\n",
    "c _ { 1 } \\left( \\begin{array} { l } { 1 } \\\\ { 1 } \\end{array} \\right) , c _ { 2 } \\left( \\begin{array} { c } { - 1 } \\\\ { 1 } \\end{array} \\right)\n",
    "$$\n",
    "其中对应的特征向量分别是一个通解， c_{1} 和 c_{2} 可以取任意实数。那么标准化后的特征向量为:\n",
    "$$\n",
    "\\left( \\begin{array} { c } { \\frac { 1 } { \\sqrt { 2 } } } \\\\ { \\frac { 1 } { \\sqrt { 2 } } } \\end{array} \\right) , \\left( \\begin{array} { c } { - \\frac { 1 } { \\sqrt { 2 } } } \\\\ { \\frac { 1 } { \\sqrt { 2 } } } \\end{array} \\right)\n",
    "$$\n",
    "矩阵P为：\n",
    "$$\n",
    "P = \\left( \\begin{array} { c c } { \\frac { 1 } { \\sqrt { 2 } } } & { \\frac { 1 } { \\sqrt { 2 } } } \\\\ { - \\frac { 1 } { \\sqrt { 2 } } } & { \\frac { 1 } { \\sqrt { 2 } } } \\end{array} \\right)\n",
    "$$\n",
    "最后我们用P的第一行乘以数据矩阵X，就得到了降维后的表示:\n",
    "$$\n",
    "Y = \\left( \\begin{array} { c c } { \\frac { 1 } { \\sqrt { 2 } } } & { \\frac { 1 } { \\sqrt { 2 } } } \\end{array} \\right) \\left( \\begin{array} { c c c c c } { - 1 } & { - 1 } & { 0 } & { 2 } & { 0 } \\\\ { - 2 } & { 0 } & { 0 } & { 1 } & { 1 } \\end{array} \\right) = \\left( \\begin{array} { c c c c } { - \\frac { 3 } { \\sqrt { 2 } } } & { - \\frac { 1 } { \\sqrt { 2 } } } & { 0 } & { \\frac { 3 } { \\sqrt { 2 } } } & { - \\frac { 1 } { \\sqrt { 2 } } } \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pic2.zhimg.com/80/v2-f5b0a7ae6d0b400e65220a02a0f0c1c1_hd.jpg'\n",
    "IPython.display.Image(url, width = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 奇异值分解和应用\n",
    "\n",
    "SVD英文是 Singular Value Decomposition，一般简称为 SVD。下面先给出它大概的意思：\n",
    "\n",
    "对于任意一个$m \\times n $的矩阵$M$，不妨假设$m > n$，它可以被分解为$M = UDV^{T}$\n",
    "\n",
    "其中\n",
    "\n",
    "- $U$ 是一个$m \\times n$的矩阵，满足$U^{T}U = I_{n}$，$I_{n}$ 是$n \\times n$的单位阵\n",
    "- $V$ 是一个$n \\times n$的矩阵，满足$V^{T}V = I_{n}$\n",
    "- $D$ 是一个$n \\times n$的对角矩阵，所有的元素都非负\n",
    "\n",
    "上面这短短的三条可以引发出 SVD 许多重要的性质。</p>\n",
    "\n",
    "<p>前面的表达式$M = UDV^{T}$可以用一种更容易理解的方式表达出来。如果我们把矩阵$U$用它的列向量表示出来，可以写成</p>\n",
    "\n",
    "<p>$U = (u_1, u_2,\\ldots, u_n)$</p>\n",
    "\n",
    "<p>其中每一个$u_i$被称为$M$的左奇异向量。类似地，对于$V$，有</p>\n",
    "\n",
    "<p>$V = (v_1,v_2,\\ldots,v_n)$</p>\n",
    "\n",
    "<p>它们被称为右奇异向量。再然后，假设矩阵$D$的对角线元素为$d_i$（它们被称为$M$的奇异值）并按降序排列，那么$M$就可以表达为</p>\n",
    "\n",
    "$M = d_1u_1v_1^T + d_2u_2v_2^T + \\cdots + d_nu_nv_n^T = \\sum_{i=1}^n d_iu_iv_i^T = \\sum_{i=1}^n A_i$\n",
    "\n",
    "<p>其中$A_i = d_iu_iv_i^T$是一个$m \\times n$的矩阵。换句话说，我们把原来的矩阵$M$表达成了$n$个矩阵的和。</p>\n",
    "\n",
    "<p>这个式子有什么用呢？注意到，我们假定$d_i$是按降序排列的，它在某种程度上反映了对应项$A_i$在$M$中的“贡献”。$d_i$越大，说明对应的 $A_i$在$M$的分解中占据的比重也越大。所以一个很自然的想法是，我们是不是可以提取出$A_i$中那些对$M$贡献最大的项，把它们的和作为对 $M$的近似？也就是说，如果令</p>\n",
    "\n",
    "<p>$ M_k = \\sum_{i=1}^k A_i$</p>\n",
    "\n",
    "<p>那么我们是否可以用$M_k$来对$M_n \\equiv M$进行近似？</p>\n",
    "\n",
    "<p>答案是肯定的，主成分分析就是这样做的。在主成分分析中，我们把数据整体的变异分解成若干个主成分之和，然后保留方差最大的若干个主成分，而舍弃那些方差较小的。事实上，主成分分析就是对数据的协方差矩阵进行了类似的分解（特征值分解），但这种分解只适用于对称的矩阵，而 SVD 则是对任意大小和形状的矩阵都成立。</p>\n",
    "\n",
    "<p>主成分分析降维就是用几组低维的主成分来记录原始数据的大部分信息，这也可以认为是一种信息的（有损）压缩。在 SVD 中也可以做类似的事情，也就是用更少项的求和$M_k$来近似完整的$n$项求和。为什么要这么做呢？我们用一个图像压缩的例子来说明。</p>\n",
    "\n",
    "<p>我们知道，电脑上的图像（特指位图）都是由像素点组成的，所以存储一张 1000×622 大小的图片，实际上就是存储一个 1000×622 的矩阵，共 622000 个元素。这个矩阵用 SVD 可以分解为 622 个矩阵之和，如果我们选取其中的前 100 个之和作为对图像数据的近似，那么只需要存储 100 个奇异值$d_i$，100 个$u_i$向量和 100 个$v_i$向量，共计 100×(1+1000+622)=162300个 元素，大约只有原始的 26% 大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena = imread('data/lena512color.tiff') \n",
    "imshow(lena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_img(u, sigma, v, p): #p表示奇异值的百分比\n",
    "    #print (p)\n",
    "    m = len(u)\n",
    "    n = len(v)\n",
    "    a = np.zeros((m, n))\n",
    "    \n",
    "    count = (int)(sum(sigma))\n",
    "    curSum = 0\n",
    "    k = 0\n",
    "    while curSum <= count * p:\n",
    "        uk = u[:, k].reshape(m, 1)\n",
    "        vk = v[k].reshape(1, n)\n",
    "        a += sigma[k] * np.dot(uk, vk)\n",
    "        curSum += sigma[k]\n",
    "        k += 1\n",
    "    #print ('k:',k)\n",
    "    a[a < 0] = 0\n",
    "    a[a > 255] = 255\n",
    "    #按照最近距离取整数，并设置参数类型为uint8\n",
    "    return np.rint(a).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_img = {}\n",
    "a = lena\n",
    "for i in tqdm(range(1,11)):\n",
    "    p = i/10\n",
    "    u, sigma, v = np.linalg.svd(a[:, :, 0])\n",
    "    R = rebuild_img(u, sigma, v, p)\n",
    "\n",
    "    u, sigma, v = np.linalg.svd(a[:, :, 1])\n",
    "    G = rebuild_img(u, sigma, v, p)\n",
    "\n",
    "    u, sigma, v = np.linalg.svd(a[:, :, 2])\n",
    "    B = rebuild_img(u, sigma, v, p)\n",
    "\n",
    "    reconstructed_img[i] = np.stack((R, G, B), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,5,figsize=(20,8))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i,j].imshow(reconstructed_img[i*5+j+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 应用实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_data = pd.read_csv('data/select_table_chn.csv',index_col=0)\n",
    "rate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mx = np.array(rate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### screen plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_solver = ['auto','full','arpack','randomized']\n",
    "pca = PCA(svd_solver=svd_solver[0])\n",
    "input_mx_ = StandardScaler().fit_transform(input_mx) #scale for columns\n",
    "pca.fit(input_mx_)\n",
    "#loadings = np.dot(np.diag(pca.singular_values_), pca.components_)\n",
    "#how to reverse back: (X - np.mean(X, axis=0).reshape((1, -1))).dot(pca.components_.T)[0]\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "plot_data = pd.DataFrame(np.concatenate((np.arange(1,pca.explained_variance_ratio_.shape[0]+1).reshape(-1,1).astype('int'),\n",
    "                                         pca.explained_variance_ratio_.reshape(-1,1)),axis=1),columns=['Dimension','Percentage of explained variance'])\n",
    "sns.barplot(data=plot_data,x='Dimension',y='Percentage of explained variance',color='blue',alpha=0.8)\n",
    "ax=std_plot(ax,'Dimension','Percentage of explained variance','Screen Plot',\n",
    "            xticklabel=np.arange(1,pca.explained_variance_ratio_.shape[0]+1),\n",
    "            legendscale=False,legend_adj=False)\n",
    "fig.tight_layout()\n",
    "#embed_pdf_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroMean(dataMat):      \n",
    "    meanVal=np.mean(dataMat,axis=0)     #按列求均值，即求各个特征的均值\n",
    "    newData=dataMat-meanVal\n",
    "    return newData,meanVal\n",
    " \n",
    "def pca_own(dataMat,n=None):\n",
    "    if n==None:\n",
    "        n = dataMat.shape[1]\n",
    "    newData,meanVal=zeroMean(dataMat)\n",
    "    covMat=np.cov(newData,rowvar=0)    #求协方差矩阵,return ndarray；若rowvar非0，一列代表一个样本，为0，一行代表一个样本\n",
    "    \n",
    "    eigVals,eigVects=np.linalg.eig(np.mat(covMat))#求特征值和特征向量,特征向量是按列放的，即一列代表一个特征向量\n",
    "    eigValIndice=np.argsort(eigVals)            #对特征值从小到大排序\n",
    "    n_eigValIndice=eigValIndice[-1:-(n+1):-1]   #最大的n个特征值的下标\n",
    "    n_eigVect=eigVects[:,n_eigValIndice]        #最大的n个特征值对应的特征向量\n",
    "    lowDDataMat=newData*n_eigVect               #低维特征空间的数据\n",
    "    reconMat=(lowDDataMat*n_eigVect.T)+meanVal  #重构数据\n",
    "    return lowDDataMat,reconMat,n_eigVect\n",
    "\n",
    "lowDDataMat,pca_mx,loadings = pca_own(input_mx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDDataMat.shape,pca_mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,60))\n",
    "sns.heatmap(lowDDataMat,ax=ax,vmin=-1, vmax=1, annot=True, fmt='.2f', cmap='vlag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_img = {}\n",
    "a = lena\n",
    "for i in tqdm(range(1,11)):\n",
    "    p = i*2/100\n",
    "    print (p)\n",
    "    dim_retain = int(a.shape[0] * p)\n",
    "    reconstructed_img[i] = np.zeros([a.shape[0],a.shape[1],a.shape[2]])\n",
    "    for j in range(a.shape[2]):\n",
    "        _,reconstructed_img[i][:,:,j],_ = pca_own(a[:,:,j],dim_retain)\n",
    "    reconstructed_img[i] = reconstructed_img[i].astype('int')\n",
    "    reconstructed_img[i][reconstructed_img[i]<=0] = 0\n",
    "    reconstructed_img[i][reconstructed_img[i]>=255] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,5,figsize=(20,8))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i,j].imshow(reconstructed_img[i*5+j+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_columns = np.array([i.split('-')[2]+'-month' for i in rate_data.columns])\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "#loadings_test = pca.components_*np.sqrt(pca.singular_values_)\n",
    "sns.heatmap(loadings.T,ax=ax,vmin=-1, vmax=1, annot=True, fmt='.2f', cmap='vlag')\n",
    "ax.set_title('PCA loading matrix')\n",
    "ax.set_ylabel('PCs')\n",
    "ax.set_xlabel('Variables')\n",
    "ax.set_xticklabels(revise_columns,fontsize=10,rotation=90)\n",
    "ax.set_yticklabels(np.array(['PC'+ str(i) for i in range(1,loadings.shape[0]+1)]))\n",
    "fig.tight_layout()\n",
    "#embed_pdf_figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_markers = ('o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X')\n",
    "fontlegend = {'family':'Arial',\n",
    "                  'weight' : 'normal', \n",
    "                  'size' : 6.5*1}\n",
    "def PCA_plot_sns(ax,data,sampleclass,method = 'Origin'):\n",
    "    #X = log_transfrom(data).T\n",
    "    X = StandardScaler().fit_transform(data.T)\n",
    "    if method=='Origin':\n",
    "        X_pca=X\n",
    "    if method == 'PCA':\n",
    "        transform = PCA()\n",
    "        X_pca = transform.fit_transform(X)\n",
    "    elif method == 'tSNE':\n",
    "        transform = TSNE()\n",
    "        X_pca = transform.fit_transform(X)\n",
    "   \n",
    "    plot_table = pd.DataFrame(X_pca[:,:2])\n",
    "    plot_table.index = data.columns\n",
    "    plot_table = pd.concat((plot_table,sampleclass.loc[plot_table.index]),axis=1)\n",
    "    plot_table.columns = ['dimension_1','dimension_2','class']\n",
    "    classnum = np.unique(plot_table.iloc[:,2]).shape[0]\n",
    "\n",
    "    sns.scatterplot(ax=ax,data=plot_table,x=\"dimension_1\", y=\"dimension_2\",markers=filled_markers,\n",
    "                    palette=legendhandle(np.unique(plot_table['class'])), hue=\"class\",style=\"class\",s=30,linewidth=0.01)\n",
    "    \n",
    "    std_plot(ax,'Dimension 1','Dimension 2',\n",
    "             title=method, legendtitle='class',legendsort=False\n",
    "             ,xbins=6,ybins=6\n",
    "            )\n",
    "    legend = ax.legend(prop=fontlegend,\n",
    "     bbox_to_anchor=(1.2,0.9),framealpha=0,labelspacing=0.24)\n",
    "    ax.legend_.get_frame()._linewidth=0\n",
    "    fig.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_table = rate_data\n",
    "year_class = pd.DataFrame(np.concatenate((np.array(input_table.index).reshape(-1,1),np.array(['y'+i.split('-')[0] for i in \n",
    "                                input_table.index]).reshape(-1,1)),axis=1),columns=['sample','label'])\n",
    "year_class = year_class.set_index('sample').astype('str')\n",
    "month_class = pd.DataFrame(np.concatenate((np.array(input_table.index).reshape(-1,1),np.array(['m'+i.split('-')[1] for i in \n",
    "                                input_table.index]).reshape(-1,1)),axis=1),columns=['sample','label'])\n",
    "month_class = month_class.set_index('sample').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(7,3))\n",
    "PCA_plot_sns(ax[0], input_table.T,year_class,'Origin')\n",
    "PCA_plot_sns(ax[1], input_table.T,year_class,'PCA')\n",
    "#embed_pdf_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "https://www.jiqizhixin.com/articles/2017-11-13-7<br>\n",
    "http://www.datakit.cn/blog/2017/02/05/t_sne_full.html<br>\n",
    "http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/<br>\n",
    "[t-SNE使用中的问题](http://bindog.github.io/blog/2018/07/31/t-sne-tips/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('http://bindog.github.io/blog/2018/07/31/t-sne-tips/', width=800, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(9,3))\n",
    "PCA_plot_sns(ax[0],input_table.T,month_class,'Origin')\n",
    "PCA_plot_sns(ax[1],input_table.T,month_class,'PCA')\n",
    "PCA_plot_sns(ax[2],input_table.T,month_class,'tSNE')\n",
    "fig.tight_layout()\n",
    "#embed_pdf_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Processing: principles and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc, argparse, sys, os, errno\n",
    "from IPython.core.display import HTML,Image\n",
    "from functools import reduce\n",
    "import h5py\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,auc\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from bokeh.palettes import Category20c,Set3,Pastel2\n",
    "from ipywidgets import interact,interactive, FloatSlider,IntSlider, RadioButtons,Dropdown,Tab,Text\n",
    "from IPython.core.display import HTML,Image\n",
    "from matplotlib.backends.backend_pdf import PdfPages, PdfFile\n",
    "from IPython.display import HTML, display, FileLink\n",
    "from base64 import b64encode, b64decode\n",
    "from io import StringIO, BytesIO\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~chenxupeng/projects/exSEEK_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure template\n",
    "figure_template_path = 'bin'\n",
    "if figure_template_path not in sys.path:\n",
    "    sys.path.append(figure_template_path)\n",
    "from importlib import reload\n",
    "import figure_template\n",
    "# force reload of the module\n",
    "reload(figure_template)\n",
    "from figure_template import display_dataframe, embed_pdf_figure, embed_pdf_pages,std_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     25
    ]
   },
   "outputs": [],
   "source": [
    "fontsize = 6.5\n",
    "fontscale = 1\n",
    "fontweight =  'normal'\n",
    "fonttitle = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "                  'size' : fontsize*fontscale}\n",
    "fontlabel = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "                  'size' : fontsize*fontscale}\n",
    "fontticklabel = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "                  'size' : fontsize*fontscale}\n",
    "fontlegend = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "              #'linewidth':0.5,\n",
    "                  'size' : fontsize*fontscale}\n",
    "fontcbarlabel = {'family':'Arial',\n",
    "                 'weight' : fontweight, \n",
    "                 #'Rotation' : 270,\n",
    "                 #'labelpad' : 25,\n",
    "                 'size' : fontsize*fontscale}\n",
    "fontcbarticklabel = {'family':'Arial',#Helvetica\n",
    "                 'weight' : fontweight, \n",
    "                 'size' : (fontsize-1)*fontscale}\n",
    "\n",
    "def std_plot(ax,xlabel=None,ylabel=None,title=None,\n",
    "             legendtitle=None,bbox_to_anchor=None,\n",
    "             labelspacing=0.2,borderpad=0.2,handletextpad=0.2,legendsort=False,markerscale=None,\n",
    "             xlim=None,ylim=None,\n",
    "             xbins=None,ybins=None,\n",
    "             cbar=None,cbarlabel=None,\n",
    "             moveyaxis=False,sns=False,left=True,rotation=None,xticklabel=None,legendscale=True,h=None,l=None,**kwards):\n",
    "        # height = 2 font = 6.5\n",
    "    def autoscale(fig):\n",
    "        if isinstance(fig,matplotlib.figure.Figure):\n",
    "            width,height = fig.get_size_inches()\n",
    "        elif isinstance(fig,matplotlib.axes.Axes):\n",
    "            width,height = fig.figure.get_size_inches()\n",
    "        fontscale = height/2\n",
    "        if width/fontscale > 8:\n",
    "            warnings.warn(\"Please reset fig's width. When scaling the height to 2 in, the scaled width '%.2f' is large than 8\"%(width/fontscale),UserWarning)\n",
    "        return fontscale\n",
    "    \n",
    "    class fontprop:\n",
    "        def init(self,fonttitle=None,fontlabel=None,fontticklabel=None,fontlegend=None,fontcbarlabel=None,fontcbarticklabel=None):\n",
    "            self.fonttitle = fonttitle\n",
    "            self.fontlabel = fontlabel\n",
    "            self.fontticklabel = fontticklabel\n",
    "            self.fontlegend = fontlegend\n",
    "            self.fontcbarlabel = fontcbarlabel\n",
    "            self.fontcbarticklabel = fontcbarticklabel\n",
    "        def update(self,fontscale):\n",
    "            self.fonttitle['size'] = self.fonttitle['size']*fontscale\n",
    "            self.fontlabel['size'] = self.fontlabel['size']*fontscale\n",
    "            self.fontticklabel['size'] = self.fontticklabel['size']*fontscale\n",
    "            self.fontlegend['size'] = self.fontlegend['size']*fontscale\n",
    "            self.fontcbarlabel['size'] = self.fontcbarlabel['size']*fontscale\n",
    "            self.fontcbarticklabel['size'] = self.fontcbarticklabel['size']*fontscale\n",
    "        def reset(self,fontscale):\n",
    "            self.fonttitle['size'] = self.fonttitle['size']/fontscale\n",
    "            self.fontlabel['size'] = self.fontlabel['size']/fontscale\n",
    "            self.fontticklabel['size'] = self.fontticklabel['size']/fontscale\n",
    "            self.fontlegend['size'] = self.fontlegend['size']/fontscale\n",
    "            self.fontcbarlabel['size'] = self.fontcbarlabel['size']/fontscale\n",
    "            self.fontcbarticklabel['size'] = self.fontcbarticklabel['size']/fontscale\n",
    "    fontscale = autoscale(ax)\n",
    "    font = fontprop()\n",
    "    font.init(fonttitle,fontlabel,fontticklabel,fontlegend,fontcbarlabel,fontcbarticklabel)\n",
    "    font.update(fontscale)\n",
    "    \n",
    "    pyplot.draw()\n",
    "    #plt.figure(linewidth=30.5)\n",
    "    if xlim is not None:  \n",
    "        ax.set(xlim=xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set(ylim=ylim)\n",
    "    #pyplot.draw()\n",
    "    if xbins is not None:\n",
    "        locator = MaxNLocator(nbins=xbins)\n",
    "        locator.set_axis(ax.xaxis)\n",
    "        ax.set_xticks(locator())\n",
    "    if ybins is not None:\n",
    "        locator = MaxNLocator(nbins=ybins)\n",
    "        locator.set_axis(ax.yaxis)\n",
    "        ax.set_yticks(locator())\n",
    "    pyplot.draw()\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_xlabel(xlabel,fontdict = font.fontlabel,labelpad=(fontsize-1)*fontscale)\n",
    "    ax.set_ylabel(ylabel,fontdict = font.fontlabel,labelpad=(fontsize-1)*fontscale)\n",
    "    if (rotation is not None) & (xticklabel is not None) :\n",
    "        ax.set_xticklabels(xticklabel,fontticklabel,rotation=rotation)\n",
    "    elif (xticklabel is not None) &(rotation is None):\n",
    "        ax.set_xticklabels(xticklabel,fontticklabel)\n",
    "    elif (xticklabel is None) &(rotation is None):\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),fontticklabel)\n",
    "    elif (rotation is not None) & (xticklabel is None):\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),fontticklabel,rotation=rotation)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(),font.fontticklabel)\n",
    "\n",
    "    if moveyaxis is True:\n",
    "        #fontticklabel \n",
    "        ax.spines['left'].set_position(('data',0))\n",
    "    ax.spines['left'].set_visible(left)\n",
    "    ax.spines['right'].set_visible(not left)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_linewidth(0.5*fontscale)\n",
    "    ax.spines['bottom'].set_linewidth(0.5*fontscale)\n",
    "    ax.spines['left'].set_linewidth(0.5*fontscale)\n",
    "    ax.spines['bottom'].set_color('k')\n",
    "    ax.spines['left'].set_color('k')\n",
    "    ax.spines['right'].set_color('k')\n",
    "    \n",
    "    ax.tick_params(direction='out', pad=2*fontscale,width=0.5*fontscale)\n",
    "    #ax.spines['bottom']._edgecolor=\"#000000\"\n",
    "    #ax.spines['left']._edgecolor=\"#000000\"\n",
    "    if title is not None:\n",
    "        ax.set_title(title,fontdict = font.fonttitle)\n",
    "    if legendscale is True:\n",
    "        if (h is None)&(l is None):\n",
    "            legend = ax.legend(prop=font.fontlegend,\n",
    "                  bbox_to_anchor=bbox_to_anchor,\n",
    "                  labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "        else:\n",
    "            legend = ax.legend(h,l,prop=font.fontlegend,\n",
    "                  bbox_to_anchor=bbox_to_anchor,\n",
    "                  labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "    if legendtitle is not None:\n",
    "        #if legendloc is None:\n",
    "        #    legendloc=\"best\"\n",
    "        legend = ax.legend(title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "        ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "        legend.get_title().set_fontweight('normal')\n",
    "        legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "        if legendsort is True:\n",
    "            # h: handle l:label\n",
    "            h,l = ax.get_legend_handles_labels()\n",
    "            l,h = zip(*sorted(zip(l,h), key=lambda t: int(t[0]))) \n",
    "            legend = ax.legend(h,l,title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "            ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "            legend.get_title().set_fontweight('normal')\n",
    "            legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "        if sns is True:\n",
    "            h,l = ax.get_legend_handles_labels()\n",
    "            #l,h = zip(*sorted(zip(l,h), key=lambda t: int(t[0]))) \n",
    "            legend = ax.legend(h[1:],l[1:],title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "            ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "            legend.get_title().set_fontweight('normal')\n",
    "            legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "    else:\n",
    "        legend = ax.legend(handles=h,labels=l,title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "        ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "        legend.get_title().set_fontweight('normal')\n",
    "        legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "\n",
    "    if cbar is not None:\n",
    "        #locator, formatter = cbar._get_ticker_locator_formatter()\n",
    "        #ticks, ticklabels, offset_string = cbar._ticker(locator, formatter)\n",
    "        #cbar.ax.spines['top'].set_visible(False)\n",
    "        #cbar.ax.spines['right'].set_visible(False)\n",
    "        #cbar.ax.spines['bottom'].set_visible(False)\n",
    "        #cbar.ax.spines['left'].set_visible(False)\n",
    "        cbar.ax.tick_params(direction='out', pad=3*fontscale,width=0*fontscale,length=0*fontscale)\n",
    "        cbar.set_label(cbarlabel,fontdict = font.fontcbarlabel,Rotation=270,labelpad=fontscale*(fontsize+1))\n",
    "        cbar.ax.set_yticks(cbar.ax.get_yticks())\n",
    "        cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(),font.fontcbarticklabel)\n",
    "    font.reset(fontscale)\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = '/home/chenxupeng/projects/exSEEK_training/'+'output/'+'fig3'+'/'\n",
    "\n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(Pastel2[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau10m = np.array([(114,158,206),(255,158,74),(103,191,92),(237,102,93),(173,139,201),\n",
    "                       (168,120,110),(237,151,202),(162,162,162),(205,204,93),(109,204,218)])/255\n",
    "sns.palplot(tableau10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(Set3[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau10l5 = np.array([(196,156,148),(247,182,210),(199,199,199),(219,219,141),(158,218,229)])/255\n",
    "sns.palplot(tableau10l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau20 = np.array([(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),  \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),  \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),  \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),  \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)])/255.\n",
    "sns.palplot(tableau20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legendhandle(lists,porm=True,order=0):\n",
    "    '''\n",
    "        input: array,porm palette or marker\n",
    "        palettesorder=0 dataset Category20c\n",
    "        palettesorder=1 batch\n",
    "\n",
    "        return a dic mapping levels of the hue variable to colors\n",
    "        or return a dic mapping levels of the style variable to markers\n",
    "        when use sns function, set palette=dic or markers=dic\n",
    "\n",
    "    '''\n",
    "    if porm == True:\n",
    "        if order == 0:\n",
    "            palette = np.array(Category20c[20]).reshape(4,-1).T.ravel()\n",
    "        if order == 1:\n",
    "            palette = Set3[12]\n",
    "        lists.sort()\n",
    "        dic={}\n",
    "        for i in range(len(lists)):\n",
    "            dic[lists[i]]=palette[i]\n",
    "        return dic\n",
    "    else:\n",
    "        markerlist1 = ['v','^','<','>'] #triangle_down triangle_up triangle_left triangle_left\n",
    "        markerlist2 = ['P','o','X','s'] #plus (filled) circle x (filled) square\n",
    "        #markerlist3 = ['$CPM$','$CPM_top$','$RLE$','$TMM$']\n",
    "        markerlist3 = ['$f$','$g$','$h$','$l$']\n",
    "        markerlist3.sort()\n",
    "        if order == 0:\n",
    "            markers = markerlist2\n",
    "        if order == 1:\n",
    "            markers = markerlist1\n",
    "        if order == 2:\n",
    "            markers = markerlist3\n",
    "            \n",
    "        lists.sort()\n",
    "        dic={}\n",
    "        for i in range(len(lists)):\n",
    "            dic[lists[i]]=markers[i]\n",
    "        return dic       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "legendhandle(np.unique(tips['smoker']),True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"day\", y=\"total_bill\", hue=\"smoker\",data=tips, palette=legendhandle(np.unique(tips['smoker']),True,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legendhandle(np.unique(tips['smoker']),True,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.boxplot(x=\"day\", y=\"total_bill\", hue=\"smoker\",data=tips, palette=legendhandle(np.unique(tips['smoker']),True,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ['Norm_RLE', 'Norm_RLE', 'Norm_RLE', 'Norm_RLE', 'Norm_CPM',\n",
    "       'Norm_CPM', 'Norm_CPM', 'Norm_CPM', 'Norm_CPM_top', 'Norm_CPM_top',\n",
    "       'Norm_CPM_top', 'Norm_CPM_top', 'Norm_TMM', 'Norm_TMM', 'Norm_TMM',\n",
    "       'Norm_TMM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legendhandle(np.unique(A),False,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plotRLE(mat,batch=None,label=None,logged=False,path=None,filename=None,title=None):\n",
    "    \"\"\"\n",
    "    mat: DataFrame, expression matrix\n",
    "    batch: DataFrame, optional, if given, batch.index must be contained in mat.columns\n",
    "    label: One of batch.columns by which the samples are grouped in the figure\n",
    "    \"\"\"\n",
    "    log_mat = mat if logged else np.log2(mat+1)\n",
    "    feature_meds = log_mat.apply(np.median,1).tolist()\n",
    "    for i in np.arange(len(feature_meds)):\n",
    "        log_mat.iloc[i] = log_mat.iloc[i] - feature_meds[i]\n",
    "    mat_rle = log_mat\n",
    "    distance = 0\n",
    "    for i in range(mat_rle.shape[1]):\n",
    "        small,large = np.percentile(mat_rle.iloc[:,i], [25, 75])\n",
    "        distance = distance+(large-small)**2\n",
    "    score = distance/mat_rle.shape[1]\n",
    "    stack = mat_rle.stack().reset_index()\n",
    "    stack.rename(columns={stack.columns[2]:\"counts\", stack.columns[1]: \"index\"},inplace=True)\n",
    "    #stack['class'] = None\n",
    "    if batch is not None:\n",
    "        batch.index.name = 'index'\n",
    "        batch = batch[label].reset_index()\n",
    "        stack = pd.merge(stack, batch, on=['index'])\n",
    "        fig,ax = plt.subplots(figsize=(2.8,2))\n",
    "        #ax = sns.boxplot(x='index',y='counts',data=stack.sort_values(by=label),fliersize=0,linewidth=0.1,width=1,hue=label,hue_order=np.unique(np.array(stack.loc[:,label])).sort(),dodge=False)\n",
    "        ax = sns.boxplot(x='index',y='counts',data=stack.sort_values(by=label),\n",
    "                     fliersize=0,linewidth=0,width=0.8,hue=label,\n",
    "                     hue_order=np.unique(np.array(stack.loc[:,label])).sort(),\n",
    "                     notch = True,showfliers=False,showmeans=False,showcaps=False,whiskerprops=dict(linewidth=0.5,color='#D8D8D8'),\n",
    "                     dodge=False,palette=legendhandle(np.unique(stack.dataset)))  \n",
    "        ax.annotate('variation score: %.2f'%score,xy=(mat_rle.shape[1]*0.6,-3),\n",
    "                          fontfamily='Arial',fontsize=5.5)\n",
    "        ax.set(xticks=[])\n",
    "        std_plot(ax,'samples','Relative log expression',legendtitle='label',legendsort=False,title=title,ybins=4,bbox_to_anchor=(1.1,1.1),ylim=[-4,4])\n",
    "    else:\n",
    "        fig,ax = plt.subplots(figsize=(3.3,2))\n",
    "        ax = sns.boxplot(x='index',y='counts',data=stack,fliersize=0,linewidth=0.1,width=1,color='g')\n",
    "        ax.set(xticks=[])\n",
    "        std_plot(ax,'samples','RLE',legendtitle='label',legendsort=False,ylim=[-10,10],title=title,ybins=4)\n",
    "    #ax.legend_.remove()\n",
    "    legend = ax.legend(prop=fontlegend,\n",
    "                  #labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,bbox_to_anchor=(1.05, 0.75))\n",
    "    ax.legend_.get_frame()._linewidth=0\n",
    "    #ax.legend_.remove()\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    fig.tight_layout()\n",
    "    #embed_pdf_figure()\n",
    "    #fig.savefig(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normlist= ['filter.null.Norm_RLE','filter.null.Norm_CPM','filter.null.Norm_CPM_top',#'filter.null.Norm_null',\n",
    "           #'filter.null.Norm_CPM_top_5','filter.null.Norm_CPM_top_10',\n",
    "           #'filter.null.Norm_CPM_top_20','filter.null.Norm_CPM_top_40',\n",
    "           'filter.null.Norm_TMM']\n",
    "batchlist = ['Batch_ComBat_1','Batch_null','Batch_RUV','Batch_limma_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodlist = []\n",
    "for i in normlist:\n",
    "    #for j in batchlist:\n",
    "    j=batchlist[1]\n",
    "    methodlist.append(i+'.'+j)\n",
    "methodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodlist = ['filter.null.Norm_RLE.Batch_null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_info = pd.read_table('/home/xieyufeng/fig3/data/cfRNA/batch_info.txt',index_col=0)\n",
    "class_info[class_info.dataset=='lulab_hcc']='GSE123972'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = pd.read_table('/home/zhaotianxiao/fig3/batch_info.txt', index_col=0)\n",
    "class_info[class_info.dataset=='lulab_hcc']='GSE123972'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#titlelist=['CPM','CPM-top','RLE','TMM']\n",
    "titlelist=['RLE']\n",
    "j=0\n",
    "for i in tqdm((methodlist)):\n",
    "    table = pd.read_table('/home/xieyufeng/fig3/output/'+'cfRNA'+'/matrix_processing/'+i+'.mirna_and_domains.txt',\n",
    "                           index_col=0)\n",
    "    plotRLE(table,batch=class_info,label='dataset',path=savepath,filename='RLE_leg_big{}.eps'.format(i),title=titlelist[j])\n",
    "    j=j+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRLE(mat,batch=None,label=None,logged=False,path=None,filename=None,title=None):\n",
    "    \"\"\"\n",
    "    mat: DataFrame, expression matrix\n",
    "    batch: DataFrame, optional, if given, batch.index must be contained in mat.columns\n",
    "    label: One of batch.columns by which the samples are grouped in the figure\n",
    "    \"\"\"\n",
    "    log_mat = mat if logged else np.log2(mat+1)\n",
    "    feature_meds = log_mat.apply(np.median,1).tolist()\n",
    "    for i in np.arange(len(feature_meds)):\n",
    "        log_mat.iloc[i] = log_mat.iloc[i] - feature_meds[i]\n",
    "    mat_rle = log_mat\n",
    "    distance = 0\n",
    "    for i in range(mat_rle.shape[1]):\n",
    "        small,large = np.percentile(mat_rle.iloc[:,i], [25, 75])\n",
    "        distance = distance+(large-small)**2\n",
    "    score = distance/mat_rle.shape[1]\n",
    "    stack = mat_rle.stack().reset_index()\n",
    "    stack.rename(columns={stack.columns[2]:\"counts\", stack.columns[1]: \"index\"},inplace=True)\n",
    "    #stack['class'] = None\n",
    "    if batch is not None:\n",
    "        batch.index.name = 'index'\n",
    "        batch = batch[label].reset_index()\n",
    "        stack = pd.merge(stack, batch, on=['index'])\n",
    "        fig,ax = plt.subplots(figsize=(2,2))\n",
    "        #ax = sns.boxplot(x='index',y='counts',data=stack.sort_values(by=label),fliersize=0,linewidth=0.1,width=1,hue=label,hue_order=np.unique(np.array(stack.loc[:,label])).sort(),dodge=False)\n",
    "        ax = sns.boxplot(x='index',y='counts',data=stack.sort_values(by=label),\n",
    "                     fliersize=0,linewidth=0,width=0.8,hue=label,\n",
    "                     hue_order=np.unique(np.array(stack.loc[:,label])).sort(),\n",
    "                     notch = True,showfliers=False,showmeans=False,showcaps=False,whiskerprops=dict(linewidth=0.5,color='#D8D8D8'),\n",
    "                     dodge=False,palette=legendhandle(np.unique(stack.dataset)))  \n",
    "        ax.annotate('variation score: %.2f'%score,xy=(mat_rle.shape[1]*0.4,-9),\n",
    "                          fontfamily='Arial',fontsize=5.5)\n",
    "        ax.set(xticks=[])\n",
    "        std_plot(ax,'samples','Relative log expression',legendtitle='label',legendsort=False,title=title,ybins=4,bbox_to_anchor=(1.1,1.1))#,ylim=[-4,4])\n",
    "    else:\n",
    "        fig,ax = plt.subplots(figsize=(3.3,2))\n",
    "        ax = sns.boxplot(x='index',y='counts',data=stack,fliersize=0,linewidth=0.1,width=1,color='g')\n",
    "        ax.set(xticks=[])\n",
    "        std_plot(ax,'sample','RLE',legendtitle='label',legendsort=False,ylim=[-10,10],title=title,ybins=4)\n",
    "    #ax.legend_.remove()\n",
    "    legend = ax.legend(prop=fontlegend,\n",
    "                  #labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,bbox_to_anchor=(1.05, 0.75))\n",
    "    ax.legend_.get_frame()._linewidth=0\n",
    "    ax.legend_.remove()\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    fig.tight_layout()\n",
    "    #embed_pdf_figure()\n",
    "    #fig.savefig(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_table('/home/shibinbin/projects/exSeek-dev/output/cfRNA/count_matrix/mirna_and_domains.txt',\n",
    "                           index_col=0)\n",
    "plotRLE(table,batch=class_info,label='dataset',path=savepath,filename='RLE_noleg_{}.eps'.format('null'),title='Raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRLE(ax,mat,batch=None,label=None,logged=False,path=None,filename=None,title=None,ylim=None,ylabel='',color='#E5E5E5'):\n",
    "    \"\"\"\n",
    "    mat: DataFrame, expression matrix\n",
    "    batch: DataFrame, optional, if given, batch.index must be contained in mat.columns\n",
    "    label: One of batch.columns by which the samples are grouped in the figure\n",
    "    \"\"\"\n",
    "    log_mat = mat if logged else np.log2(mat+1)\n",
    "    feature_meds = log_mat.apply(np.median,1).tolist()\n",
    "    for i in np.arange(len(feature_meds)):\n",
    "        log_mat.iloc[i] = log_mat.iloc[i] - feature_meds[i]\n",
    "    mat_rle = log_mat\n",
    "    distance = 0\n",
    "    for i in range(mat_rle.shape[1]):\n",
    "        small,large = np.percentile(mat_rle.iloc[:,i], [25, 75])\n",
    "        distance = distance+(large-small)**2\n",
    "    score = distance/mat_rle.shape[1]\n",
    "    stack = mat_rle.stack().reset_index()\n",
    "    stack.rename(columns={stack.columns[2]:\"counts\", stack.columns[1]: \"index\"},inplace=True)\n",
    "    #stack['class'] = None\n",
    "    if batch is not None:\n",
    "        batch.index.name = 'index'\n",
    "        batch = batch[label].reset_index()\n",
    "        stack = pd.merge(stack, batch, on=['index'])\n",
    "        \n",
    "        #ax = sns.boxplot(x='index',y='counts',data=stack.sort_values(by=label),fliersize=0,linewidth=0.1,width=1,hue=label,hue_order=np.unique(np.array(stack.loc[:,label])).sort(),dodge=False)\n",
    "        ax = sns.boxplot(ax=ax,x='index',y='counts',data=stack.sort_values(by=label),\n",
    "                     fliersize=0,linewidth=0,width=0.8,hue=label,\n",
    "                     hue_order=np.unique(np.array(stack.loc[:,label])).sort(),\n",
    "                     notch = True,showfliers=False,showmeans=False,showcaps=False,whiskerprops=dict(linewidth=0.4,color=color),\n",
    "                     dodge=False,palette=legendhandle(np.unique(stack.dataset)))       \n",
    "        ax.set(xticks=[])\n",
    "        std_plot(ax,'Samples',ylabel,legendtitle='label',legendsort=False,title=title,ybins=4,ylim=ylim)\n",
    "        ax.annotate('$variation\\ score$: %.2f'%score,xy=(mat_rle.shape[1]*0.4,ax.get_ylim()[0]*0.9+ax.get_ylim()[1]*0.1),\n",
    "                          fontfamily='Arial',fontsize=5.5)\n",
    "    else:\n",
    "        #fig,ax = plt.subplots(figsize=(3,2))\n",
    "        ax = sns.boxplot(ax=ax,x='index',y='counts',data=stack,fliersize=0,linewidth=0.1,width=1,color='g')\n",
    "        ax.set(xticks=[])\n",
    "        std_plot(ax,'sample','RLE',legendtitle='label',legendsort=False,ylim=[-10,10],title=title,ybins=4)\n",
    "    #ax.legend_.remove()\n",
    "    legend = ax.legend(prop=fontlegend,\n",
    "                  #labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,bbox_to_anchor=(1.05, 0.75))\n",
    "    ax.legend_.get_frame()._linewidth=0\n",
    "    ax.legend_.remove()\n",
    "    ax.spines['bottom'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titlelist=['RLE','CPM','CPM-top','TMM']\n",
    "titlelist=['RLE']\n",
    "fig,axes = plt.subplots(1,len(methodlist)+1,figsize=(5,2))\n",
    "table = pd.read_table('/home/shibinbin/projects/exSeek-dev/output/cfRNA/count_matrix/mirna_and_domains.txt',\n",
    "                           index_col=0)\n",
    "plotRLE(axes[0],table,batch=class_info,label='dataset',path=savepath,filename='RLE_noleg_{}.eps'.format('null'),title='Raw',ylabel='RLE')\n",
    "j=1    \n",
    "for i in tqdm((methodlist)):\n",
    "    table = pd.read_table('/home/xieyufeng/fig3/output/'+'cfRNA'+'/matrix_processing/'+i+'.mirna_and_domains.txt',\n",
    "                           index_col=0)\n",
    "    if j==1:\n",
    "        plotRLE(axes[j],table,batch=class_info,label='dataset',path=savepath,filename='RLE_leg_big{}.eps'.format(i),title=titlelist[j-1],ylim=[-4,4],ylabel='')\n",
    "        axes[j].set_title('RLE',fontdict = fonttitle)\n",
    "    else:\n",
    "        if i=='filter.null.Norm_RLE.Batch_null':\n",
    "            plotRLE(axes[j],table,batch=class_info,label='dataset',path=savepath,filename='RLE_leg_big{}.eps'.format(i),title=i.split('.')[2],ylim=[-4,4],ylabel='',color='#B7B7B7')\n",
    "            axes[j].set_title('RLE',fontdict = fonttitle,color='r')\n",
    "        else: \n",
    "            plotRLE(axes[j],table,batch=class_info,label='dataset',path=savepath,filename='RLE_leg_big{}.eps'.format(i),title=titlelist[j-1],ylim=[-4,4],ylabel='')\n",
    "        axes[j].set(yticks=[])\n",
    "        axes[j].spines['left'].set_visible(False)\n",
    "    j=j+1\n",
    "j=j-1\n",
    "h,l =axes[j].get_legend_handles_labels()\n",
    "l=np.array(l)\n",
    "l[l=='GSE94582_NEBNext']='GSE94582_1'\n",
    "l[l=='GSE94582_Other']='GSE94582_2'\n",
    "l[l=='GSE94582_TruSeq']='GSE94582_3'\n",
    "l = l.tolist()\n",
    "legend = axes[j].legend(h,l,prop=fontlegend,\n",
    "              #labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "              edgecolor=\"#000000\",fancybox=False,bbox_to_anchor=(1.05, 0.8))\n",
    "axes[j].legend_.get_frame()._linewidth=0\n",
    "fig.tight_layout()\n",
    "#fig.savefig(savepath+'demo.eps')\n",
    "#embed_pdf_figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodlist = ['filter.null.mirna_and_domains.txt',\n",
    "              'filter.null.Norm_RLE.mirna_and_domains.txt',]\n",
    "              #'filter.null.Norm_CPM.mirna_and_domains.txt',\n",
    "              #'filter.null.Norm_CPM_top.mirna_and_domains.txt',\n",
    "              #'filter.null.Norm_TMM.mirna_and_domains.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.read_table('/home/xieyufeng/exSeek/data/matrix_processing/ref_mirbase_gid.txt',header=-1)\n",
    "batch_info = pd.read_table('/home/xieyufeng/fig3/data/cfRNA/batch_info.txt')\n",
    "batch_info.columns=['sample_id','label']\n",
    "batch_info['label'].iloc[np.where(batch_info.label=='lulab_hcc')]='GSE123972'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def heterogeneity(matlist=methodlist,class_info=batch_info,featurenum=4,featurename=None):\n",
    "    def get_box_data(boxPlotter, boxName):\n",
    "        \"\"\"\n",
    "        boxName can be either a name \"cat\" or a tuple (\"cat\", \"hue\")\n",
    "        Here we really have to duplicate seaborn code, because there is not direct access to the\n",
    "        box_data in the BoxPlotter class.\n",
    "        \"\"\"\n",
    "        cat = boxName\n",
    "        i = boxPlotter.group_names.index(cat)\n",
    "        group_data = boxPlotter.plot_data[i]\n",
    "        return group_data\n",
    "    def find_x_position_box(boxPlotter, boxName):\n",
    "        cat = boxName\n",
    "        groupPos = boxPlotter.group_names.index(cat)\n",
    "        return groupPos\n",
    "    classname = np.unique(class_info.label)\n",
    "    classname.sort()\n",
    "    colormap = pd.DataFrame(np.array([classname,tableau10m[:len(np.unique(class_info.label))].tolist()]))\n",
    "    colormap = colormap.T\n",
    "    colormap.columns=['label','color']\n",
    "    class_info = class_info.drop(np.where(class_info.label=='GSE123972')[0]).drop(np.where(class_info.label=='GSE94582')[0]).set_index('sample_id').reset_index()\n",
    "    samplemin = np.unique(class_info.label,return_counts=True)[1].min()\n",
    "    new_class_info = pd.DataFrame([])\n",
    "    for i in unique(class_info.label):\n",
    "        extra_class_info = class_info.iloc[np.where(class_info.label==i)]\n",
    "        new_class_info = new_class_info.append(extra_class_info.sample(n=samplemin))\n",
    "    new_class_info = new_class_info.sort_values(by=['label','sample_id']).set_index('sample_id').reset_index()\n",
    "    flag = 0\n",
    "    plot = pd.DataFrame()\n",
    "    for matname in matlist:\n",
    "        mat = pd.read_table('/home/shibinbin/projects/exSeek-dev/output/cfRNA/matrix_processing/'\\\n",
    "                            +matname,index_col=0)\n",
    "        mat = mat.loc[:,new_class_info.sample_id]\n",
    "        data = np.log2(mat.iloc[np.where(np.isin([i.split('|')[0] for i in mat.index],ref))]+1)\n",
    "        if flag == 0:\n",
    "            featurelist = pd.DataFrame(data.sum(axis=1))\n",
    "            featurelist.columns=['counts']\n",
    "            ref_del = featurelist.sort_values(by='counts',ascending=False).index[:featurenum].tolist()\n",
    "        data_del = data.loc[ref_del]\n",
    "        stack = pd.DataFrame(data_del.stack())\n",
    "        stack = stack.reset_index()\n",
    "        stack.columns=['feature','sample_id','log2(count+1)']\n",
    "        merge = pd.merge(stack,new_class_info,on=['sample_id'])\n",
    "        merge['state'] = matname\n",
    "        plot = plot.append(merge)\n",
    "    plot['name_state']=[plot.feature.iloc[i].split('|')[0]+'|'+plot.state.iloc[i] for i in range(len(plot.feature))]\n",
    "    #plot = plot.sort_values(by=['name_state'])\n",
    "    plot = plot.set_index('feature').reset_index()\n",
    "    for feature in np.unique(plot.feature):\n",
    "        if (feature.split('|')[0]==featurename)|(featurename==None):\n",
    "            data_sub = plot.iloc[np.where(plot.feature == feature)]\n",
    "            data_sub = data_sub.set_index('feature').reset_index()\n",
    "            #colormap = pd.DataFrame(np.array([np.unique(data_sub.label),np.array(Category20c[20]).reshape(4,-1).T.ravel()[:len(np.unique(data_sub.label))].tolist()]))\n",
    "            #colormap = colormap.T\n",
    "            #colormap.columns=['label','color']\n",
    "            #data_sub = data_sub.merge(colormap)\n",
    "            data_sub = pd.merge(data_sub, colormap, how='left', on=['label'])\n",
    "            fig,ax = plt.subplots(figsize=(3,2))\n",
    "            ylist=[0]*len(matlist)\n",
    "            data_sub_sub={}\n",
    "            merge=pd.DataFrame()\n",
    "            datasetprop=pd.DataFrame()\n",
    "            for label in np.unique(data_sub.label):\n",
    "                data_sub_sub[label] = data_sub.iloc[np.where(data_sub.label == label)]\n",
    "                #data_sub_sub[label].to_csv('./'+label+'.txt',sep='\\t')\n",
    "                for i in np.unique(data_sub_sub[label].state):\n",
    "                    a = data_sub_sub[label][data_sub_sub[label].state==i]\n",
    "                    datasetprop.loc['var',i]=np.var(a['log2(count+1)'],ddof=1)\n",
    "                    datasetprop.loc['mean',i]=np.mean(a['log2(count+1)'])\n",
    "                #score['mean']=np.mean(a['log2(count+1)'])\n",
    "                score = pd.DataFrame(datasetprop.stack()).reset_index()\n",
    "                score['dataset']='GSE113994'\n",
    "                merge = merge.append(score)\n",
    "\n",
    "\n",
    "                data_sub_sub[label]['state_sample_id'] = [data_sub_sub[label].state.iloc[i]+'|'+\\\n",
    "                                                   str(i) for i in range(len(data_sub_sub[label]))]\n",
    "                sns.pointplot(ax=ax,x=\"state_sample_id\", y=\"log2(count+1)\",palette=data_sub_sub[label].color,hue=data_sub_sub[label].label,\n",
    "                                  data=data_sub_sub[label],scale=0.2)\n",
    "                #ax.scatter(data_sub_sub.state_sample_id.tolist(),data_sub_sub['log2(count+1)'].tolist(),color=data_sub_sub.color.tolist())\n",
    "                boxPlotter = sns.categorical._BoxPlotter(data=data_sub_sub[label],x='state_sample_id',y='log2(count+1)',hue=data_sub_sub[label].label,\n",
    "                                                         order=None, hue_order=None,\n",
    "                                                             orient=None, width=.8, color=None, palette=None, saturation=.75,\n",
    "                                                             dodge=True, fliersize=5, linewidth=None)\n",
    "                linenum = len(matlist)\n",
    "                start = ax.get_xticks()[0]\n",
    "                binwidth = math.ceil((ax.get_xticks()[0]+ax.get_xticks()[-1])/linenum)\n",
    "                for loc in range(linenum):\n",
    "                    box = [boxPlotter.group_names[i] for i in range(start+loc*binwidth,start+(loc+1)*binwidth)]\n",
    "                    box_data = []\n",
    "                    for i in box:\n",
    "                        box_data.append(get_box_data(boxPlotter, i)[0]) \n",
    "                    ylim = ax.get_ylim()\n",
    "                    yRange = ylim[1] - ylim[0]\n",
    "                    lineYOffsetAxesCoord = 0.05\n",
    "                    lineYOffsetToBoxAxesCoord = 0.06\n",
    "                    lineHeightAxesCoord=0.02\n",
    "                    yOffset = lineYOffsetAxesCoord*yRange\n",
    "                    yOffsetToBox = lineYOffsetToBoxAxesCoord*yRange\n",
    "\n",
    "                    ymax = np.array(box_data).max()\n",
    "                    y = ymax + yOffsetToBox\n",
    "                    if y>=ylist[loc]:\n",
    "                        ylist[loc]=y\n",
    "            merge.rename(columns={merge.columns[0]:\"prop\", \n",
    "                      merge.columns[1]: \"state\",\n",
    "                      merge.columns[2]: \"value\"},inplace=True)\n",
    "            plotprop=pd.DataFrame()\n",
    "            for i in np.unique(merge.state):\n",
    "                b = merge[merge.state==i]\n",
    "                mean = b[b.prop=='mean'].value\n",
    "                mean_var=np.var(mean,ddof=1)\n",
    "                var= b[b.prop=='var'].value\n",
    "                mul = 1\n",
    "                for item in var:\n",
    "                    mul *= item\n",
    "                plotprop.loc[i,'mean_var']=mean_var\n",
    "                plotprop.loc[i,'var_mul']=mul\n",
    "            plotprop=plotprop.rename(index={#'filter.null.Norm_CPM.mirna_and_domains.txt':'CPM',\n",
    "                      #'filter.null.Norm_CPM_top.mirna_and_domains.txt':'CPM-top',\n",
    "                      'filter.null.Norm_RLE.mirna_and_domains.txt':'RLE',\n",
    "                      #'filter.null.Norm_TMM.mirna_and_domains.txt':'TMM',\n",
    "                      'filter.null.mirna_and_domains.txt':'Raw'})\n",
    "            display(plotprop)\n",
    "            h = lineHeightAxesCoord*yRange\n",
    "            #title = [i.split('.')[2] for i in matlist]\n",
    "            #title = ['Raw' if x == 'mirna_and_domains' else x for x in title]  \n",
    "            #title = ['Raw','RLE','CPM','CPM-top','TMM']\n",
    "            title = ['Raw','RLE']\n",
    "            for loc in range(linenum):\n",
    "                lineX, lineY = [start+loc*binwidth,start+(loc+1)*binwidth], [ylist[loc]+h,ylist[loc]+h]\n",
    "                ax.plot(lineX, lineY,color='Black',linewidth='0.5')\n",
    "                ax.annotate(title[loc]+'\\n'+'$b$: '+'%.2f'%(plotprop.loc[title[loc],'mean_var'])+'  $w$: '+'%.2f'%(plotprop.loc[title[loc],'var_mul']), \n",
    "                            xy=(np.mean([start+loc*binwidth,start+(loc+1)*binwidth]), ylist[loc]+h),\n",
    "                          xytext=(0, 1), textcoords='offset points',\n",
    "                          xycoords='data', ha='center', va='bottom', fontfamily='Arial',fontsize=5.5,\n",
    "                          clip_on=False, annotation_clip=False)\n",
    "            ax.spines['bottom'].set_visible(False)\n",
    "            ax.set_xticks([])\n",
    "            #ax.legend(h,l,prop=fontlegend)\n",
    "            #std_plot(ax,'','',legendtitle='label',legendsort=False,title=feature.split('|')[0])\n",
    "            #ax.legend_.remove()\n",
    "            std_plot(ax,'','Normalized counts',legendtitle='label',legendsort=False,title='Heterogeneity of '+feature.split('|')[0]+' expression')\n",
    "            legend = ax.legend(prop=fontlegend,\n",
    "                  #labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,bbox_to_anchor=(1, 1.0),framealpha=0,markerscale=5)\n",
    "            ax.legend_.get_frame()._linewidth=0\n",
    "            #ax.legend_.remove()\n",
    "            fig.tight_layout()\n",
    "            #embed_pdf_figure()\n",
    "            #fig.savefig(savepath+'{}_heterogeneity_noleg_2.eps'.format(feature.split('|')[0]))\n",
    "#heterogeneity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneity(featurename='hsa-miR-21-5p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneity(featurenum=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     67,
     82,
     89,
     106,
     110,
     120
    ]
   },
   "outputs": [],
   "source": [
    "def heterogeneity(matlist=methodlist,class_info=batch_info,featurenum=4,featurename1=None,featurename2=None):\n",
    "    def get_box_data(boxPlotter, boxName):\n",
    "        \"\"\"\n",
    "        boxName can be either a name \"cat\" or a tuple (\"cat\", \"hue\")\n",
    "        Here we really have to duplicate seaborn code, because there is not direct access to the\n",
    "        box_data in the BoxPlotter class.\n",
    "        \"\"\"\n",
    "        cat = boxName\n",
    "        i = boxPlotter.group_names.index(cat)\n",
    "        group_data = boxPlotter.plot_data[i]\n",
    "        return group_data\n",
    "    def find_x_position_box(boxPlotter, boxName):\n",
    "        cat = boxName\n",
    "        groupPos = boxPlotter.group_names.index(cat)\n",
    "        return groupPos\n",
    "    classname = np.unique(class_info.label)\n",
    "    classname.sort()\n",
    "    colormap = pd.DataFrame(np.array([classname,tableau10m[:len(np.unique(class_info.label))].tolist()]))\n",
    "    colormap = colormap.T\n",
    "    colormap.columns=['label','color']\n",
    "    class_info = class_info.drop(np.where(class_info.label=='GSE123972')[0]).drop(np.where(class_info.label=='GSE94582')[0]).set_index('sample_id').reset_index()\n",
    "    samplemin = np.unique(class_info.label,return_counts=True)[1].min()\n",
    "    new_class_info = pd.DataFrame([])\n",
    "    for i in unique(class_info.label):\n",
    "        extra_class_info = class_info.iloc[np.where(class_info.label==i)]\n",
    "        new_class_info = new_class_info.append(extra_class_info.sample(n=samplemin))\n",
    "    new_class_info = new_class_info.sort_values(by=['label','sample_id']).set_index('sample_id').reset_index()\n",
    "    flag = 0\n",
    "    plot = pd.DataFrame()\n",
    "    for matname in matlist:\n",
    "        mat = pd.read_table('/home/shibinbin/projects/exSeek-dev/output/cfRNA/matrix_processing/'\\\n",
    "                            +matname,index_col=0)\n",
    "        mat = mat.loc[:,new_class_info.sample_id]\n",
    "        data = np.log2(mat.iloc[np.where(np.isin([i.split('|')[0] for i in mat.index],ref))]+1)\n",
    "        if flag == 0:\n",
    "            featurelist = pd.DataFrame(data.sum(axis=1))\n",
    "            featurelist.columns=['counts']\n",
    "            ref_del = featurelist.sort_values(by='counts',ascending=False).index[:featurenum].tolist()\n",
    "        data_del = data.loc[ref_del]\n",
    "        stack = pd.DataFrame(data_del.stack())\n",
    "        stack = stack.reset_index()\n",
    "        stack.columns=['feature','sample_id','log2(count+1)']\n",
    "        merge = pd.merge(stack,new_class_info,on=['sample_id'])\n",
    "        merge['state'] = matname\n",
    "        plot = plot.append(merge)\n",
    "    plot['name_state']=[plot.feature.iloc[i].split('|')[0]+'|'+plot.state.iloc[i] for i in range(len(plot.feature))]\n",
    "    #plot = plot.sort_values(by=['name_state'])\n",
    "    plot = plot.set_index('feature').reset_index()\n",
    "    fig,ax = plt.subplots(figsize=(5,2))\n",
    "    for feature in np.unique(plot.feature):\n",
    "        if feature.split('|')[0]==featurename1:\n",
    "            print(1)\n",
    "            data_sub = plot.iloc[np.where(plot.feature == feature)]\n",
    "            data_sub = data_sub.set_index('feature').reset_index()\n",
    "            #colormap = pd.DataFrame(np.array([np.unique(data_sub.label),np.array(Category20c[20]).reshape(4,-1).T.ravel()[:len(np.unique(data_sub.label))].tolist()]))\n",
    "            #colormap = colormap.T\n",
    "            #colormap.columns=['label','color']\n",
    "            #data_sub = data_sub.merge(colormap)\n",
    "            data_sub = pd.merge(data_sub, colormap, how='left', on=['label'])\n",
    "            \n",
    "            ylist=[0]*len(matlist)\n",
    "            data_sub_sub={}\n",
    "            merge=pd.DataFrame()\n",
    "            datasetprop=pd.DataFrame()\n",
    "            for label in np.unique(data_sub.label):\n",
    "                data_sub_sub[label] = data_sub.iloc[np.where(data_sub.label == label)]\n",
    "                #data_sub_sub[label].to_csv('./'+label+'.txt',sep='\\t')\n",
    "                for i in np.unique(data_sub_sub[label].state):\n",
    "                    a = data_sub_sub[label][data_sub_sub[label].state==i]\n",
    "                    datasetprop.loc['var',i]=np.var(a['log2(count+1)'],ddof=1)\n",
    "                    datasetprop.loc['mean',i]=np.mean(a['log2(count+1)'])\n",
    "                #score['mean']=np.mean(a['log2(count+1)'])\n",
    "                score = pd.DataFrame(datasetprop.stack()).reset_index()\n",
    "                score['dataset']='GSE113994'\n",
    "                merge = merge.append(score)\n",
    "\n",
    "\n",
    "                data_sub_sub[label]['state_sample_id'] = [data_sub_sub[label].state.iloc[i]+'|'+\\\n",
    "                                                   str(i) for i in range(len(data_sub_sub[label]))]\n",
    "                d=data_sub_sub[label]\n",
    "                d.label = [ i+ '|' + featurename1 for i in d.label]\n",
    "                sns.pointplot(ax=ax,x=\"state_sample_id\", y=\"log2(count+1)\",palette=d.color,hue=d.label,\n",
    "                                  data=d,scale=0.5)\n",
    "                #ax.scatter(data_sub_sub.state_sample_id.tolist(),data_sub_sub['log2(count+1)'].tolist(),color=data_sub_sub.color.tolist())\n",
    "                boxPlotter = sns.categorical._BoxPlotter(data=data_sub_sub[label],x='state_sample_id',y='log2(count+1)',hue=data_sub_sub[label].label,\n",
    "                                                         order=None, hue_order=None,\n",
    "                                                             orient=None, width=.8, color=None, palette=None, saturation=.75,\n",
    "                                                             dodge=True, fliersize=5, linewidth=None)\n",
    "                linenum = len(matlist)\n",
    "                start = ax.get_xticks()[0]\n",
    "                binwidth = math.ceil((ax.get_xticks()[0]+ax.get_xticks()[-1])/linenum)\n",
    "                for loc in range(linenum):\n",
    "                    box = [boxPlotter.group_names[i] for i in range(start+loc*binwidth,start+(loc+1)*binwidth)]\n",
    "                    box_data = []\n",
    "                    for i in box:\n",
    "                        box_data.append(get_box_data(boxPlotter, i)[0]) \n",
    "                    ylim = ax.get_ylim()\n",
    "                    yRange = ylim[1] - ylim[0]\n",
    "                    lineYOffsetAxesCoord = 0.05\n",
    "                    lineYOffsetToBoxAxesCoord = 0.06\n",
    "                    lineHeightAxesCoord=0.02\n",
    "                    yOffset = lineYOffsetAxesCoord*yRange\n",
    "                    yOffsetToBox = lineYOffsetToBoxAxesCoord*yRange\n",
    "\n",
    "                    ymax = np.array(box_data).max()\n",
    "                    y = ymax + yOffsetToBox\n",
    "                    if y>=ylist[loc]:\n",
    "                        ylist[loc]=y\n",
    "            merge.rename(columns={merge.columns[0]:\"prop\", \n",
    "                      merge.columns[1]: \"state\",\n",
    "                      merge.columns[2]: \"value\"},inplace=True)\n",
    "            plotprop=pd.DataFrame()\n",
    "            for i in np.unique(merge.state):\n",
    "                b = merge[merge.state==i]\n",
    "                mean = b[b.prop=='mean'].value\n",
    "                mean_var=np.var(mean,ddof=1)\n",
    "                var= b[b.prop=='var'].value\n",
    "                mul = 1\n",
    "                for item in var:\n",
    "                    mul *= item\n",
    "                plotprop.loc[i,'mean_var']=mean_var\n",
    "                plotprop.loc[i,'var_mul']=mul\n",
    "            plotprop=plotprop.rename(index={#'filter.null.Norm_CPM.mirna_and_domains.txt':'CPM',\n",
    "                      #'filter.null.Norm_CPM_top.mirna_and_domains.txt':'CPM-top',\n",
    "                      'filter.null.Norm_RLE.mirna_and_domains.txt':'RLE',\n",
    "                      #'filter.null.Norm_TMM.mirna_and_domains.txt':'TMM',\n",
    "                      'filter.null.mirna_and_domains.txt':'Raw'})\n",
    "            #display(plotprop)\n",
    "            h = lineHeightAxesCoord*yRange\n",
    "            #title = [i.split('.')[2] for i in matlist]\n",
    "            #title = ['Raw' if x == 'mirna_and_domains' else x for x in title]  \n",
    "            #title = ['Raw','RLE','CPM','CPM-top','TMM']\n",
    "            title = ['Raw','RLE']\n",
    "            for loc in range(linenum):\n",
    "                lineX, lineY = [start+loc*binwidth,start+(loc+1)*binwidth], [ylist[loc]+h,ylist[loc]+h]\n",
    "                ax.plot(lineX, lineY,color='Black',linewidth='0.5')\n",
    "                ax.annotate(title[loc]+'\\n'+'$b$: '+'%.2f'%(plotprop.loc[title[loc],'mean_var'])+'  $w$: '+'%.2f'%(plotprop.loc[title[loc],'var_mul']), \n",
    "                            xy=(np.mean([start+loc*binwidth,start+(loc+1)*binwidth]), ylist[loc]+h),\n",
    "                          xytext=(0, 1), textcoords='offset points',\n",
    "                          xycoords='data', ha='center', va='bottom', fontfamily='Arial',fontsize=5.5,\n",
    "                          clip_on=False, annotation_clip=False)\n",
    "                \n",
    "        if feature.split('|')[0]==featurename2:\n",
    "            print(2)\n",
    "            data_sub = plot.iloc[np.where(plot.feature == feature)]\n",
    "            data_sub = data_sub.set_index('feature').reset_index()\n",
    "            #colormap = pd.DataFrame(np.array([np.unique(data_sub.label),np.array(Category20c[20]).reshape(4,-1).T.ravel()[:len(np.unique(data_sub.label))].tolist()]))\n",
    "            #colormap = colormap.T\n",
    "            #colormap.columns=['label','color']\n",
    "            #data_sub = data_sub.merge(colormap)\n",
    "            data_sub = pd.merge(data_sub, colormap, how='left', on=['label'])\n",
    "            ylist=[100]*len(matlist)\n",
    "            data_sub_sub={}\n",
    "            merge=pd.DataFrame()\n",
    "            datasetprop=pd.DataFrame()\n",
    "            for label in np.unique(data_sub.label):\n",
    "                data_sub_sub[label] = data_sub.iloc[np.where(data_sub.label == label)]\n",
    "                #data_sub_sub[label].to_csv('./'+label+'.txt',sep='\\t')\n",
    "                for i in np.unique(data_sub_sub[label].state):\n",
    "                    a = data_sub_sub[label][data_sub_sub[label].state==i]\n",
    "                    datasetprop.loc['var',i]=np.var(a['log2(count+1)'],ddof=1)\n",
    "                    datasetprop.loc['mean',i]=np.mean(a['log2(count+1)'])\n",
    "                #score['mean']=np.mean(a['log2(count+1)'])\n",
    "                score = pd.DataFrame(datasetprop.stack()).reset_index()\n",
    "                score['dataset']='GSE113994'\n",
    "                merge = merge.append(score)\n",
    "\n",
    "\n",
    "                data_sub_sub[label]['state_sample_id'] = [data_sub_sub[label].state.iloc[i]+'|'+\\\n",
    "                                                   str(i) for i in range(len(data_sub_sub[label]))]\n",
    "                d = data_sub_sub[label]\n",
    "                d.label = [ i+ '|' + featurename2 for i in d.label]\n",
    "                sns.pointplot(ax=ax,x=\"state_sample_id\", y=\"log2(count+1)\",palette=d.color,hue=d.label,\n",
    "                                  data=d,scale=0.5,linestyles='--',markers='X')\n",
    "                #ax.scatter(data_sub_sub.state_sample_id.tolist(),data_sub_sub['log2(count+1)'].tolist(),color=data_sub_sub.color.tolist())\n",
    "                boxPlotter = sns.categorical._BoxPlotter(data=data_sub_sub[label],x='state_sample_id',y='log2(count+1)',hue=data_sub_sub[label].label,\n",
    "                                                         order=None, hue_order=None,\n",
    "                                                             orient=None, width=.8, color=None, palette=None, saturation=.75,\n",
    "                                                             dodge=True, fliersize=5, linewidth=None)\n",
    "                linenum = len(matlist)\n",
    "                start = ax.get_xticks()[0]\n",
    "                binwidth = math.ceil((ax.get_xticks()[0]+ax.get_xticks()[-1])/linenum)\n",
    "                for loc in range(linenum):\n",
    "                    box = [boxPlotter.group_names[i] for i in range(start+loc*binwidth,start+(loc+1)*binwidth)]\n",
    "                    box_data = []\n",
    "                    for i in box:\n",
    "                        box_data.append(get_box_data(boxPlotter, i)[0]) \n",
    "                    ylim = ax.get_ylim()\n",
    "                    yRange = ylim[1] - ylim[0]\n",
    "                    lineYOffsetAxesCoord = 0.05\n",
    "                    lineYOffsetToBoxAxesCoord = 0.06\n",
    "                    lineHeightAxesCoord=0.02\n",
    "                    yOffset = lineYOffsetAxesCoord*yRange\n",
    "                    yOffsetToBox = lineYOffsetToBoxAxesCoord*yRange\n",
    "\n",
    "                    ymin = np.array(box_data).min()\n",
    "                    y = ymin - yOffsetToBox\n",
    "                    if y<=ylist[loc]:\n",
    "                        ylist[loc]=y\n",
    "            merge.rename(columns={merge.columns[0]:\"prop\", \n",
    "                      merge.columns[1]: \"state\",\n",
    "                      merge.columns[2]: \"value\"},inplace=True)\n",
    "            plotprop=pd.DataFrame()\n",
    "            for i in np.unique(merge.state):\n",
    "                b = merge[merge.state==i]\n",
    "                mean = b[b.prop=='mean'].value\n",
    "                mean_var=np.var(mean,ddof=1)\n",
    "                var= b[b.prop=='var'].value\n",
    "                mul = 1\n",
    "                for item in var:\n",
    "                    mul *= item\n",
    "                plotprop.loc[i,'mean_var']=mean_var\n",
    "                plotprop.loc[i,'var_mul']=mul\n",
    "            plotprop=plotprop.rename(index={#'filter.null.Norm_CPM.mirna_and_domains.txt':'CPM',\n",
    "                      #'filter.null.Norm_CPM_top.mirna_and_domains.txt':'CPM-top',\n",
    "                      'filter.null.Norm_RLE.mirna_and_domains.txt':'RLE',\n",
    "                      #'filter.null.Norm_TMM.mirna_and_domains.txt':'TMM',\n",
    "                      'filter.null.mirna_and_domains.txt':'Raw'})\n",
    "            #display(plotprop)\n",
    "            h = lineHeightAxesCoord*yRange\n",
    "            #title = [i.split('.')[2] for i in matlist]\n",
    "            #title = ['Raw' if x == 'mirna_and_domains' else x for x in title]  \n",
    "            #title = ['Raw','RLE','CPM','CPM-top','TMM']\n",
    "            title = ['Raw','RLE']\n",
    "            for loc in range(linenum):\n",
    "                lineX, lineY = [start+loc*binwidth,start+(loc+1)*binwidth], [ylist[loc]-h,ylist[loc]-h]\n",
    "                ax.plot(lineX, lineY,color='Black',linewidth='0.5')\n",
    "                ax.annotate(title[loc]+'\\n'+'$b$: '+'%.2f'%(plotprop.loc[title[loc],'mean_var'])+'  $w$: '+'%.2f'%(plotprop.loc[title[loc],'var_mul']), \n",
    "                            xy=(np.mean([start+loc*binwidth,start+(loc+1)*binwidth]), ylist[loc]-20*h),\n",
    "                          xytext=(0, 1), textcoords='offset points',\n",
    "                          xycoords='data', ha='center', va='bottom', fontfamily='Arial',fontsize=5.5,\n",
    "                          clip_on=False, annotation_clip=False)\n",
    "                \n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    #ax.legend(h,l,prop=fontlegend)\n",
    "    #std_plot(ax,'','',legendtitle='label',legendsort=False,title=feature.split('|')[0])\n",
    "    #ax.legend_.remove()\n",
    "    std_plot(ax,'','Normalized counts',legendtitle='label',legendsort=False,title='Expression heterogeneity of reference genes')\n",
    "    legend = ax.legend(prop=fontlegend,\n",
    "          #labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "          edgecolor=\"#000000\",fancybox=False,bbox_to_anchor=(1, 0.8),framealpha=0,markerscale=2)\n",
    "    ax.legend_.get_frame()._linewidth=0\n",
    "    #ax.legend_.remove()\n",
    "    fig.tight_layout()\n",
    "    #embed_pdf_figure()\n",
    "    #fig.savefig(savepath+'{}_heterogeneity_noleg_2.eps'.format(feature.split('|')[0]))\n",
    "#heterogeneity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterogeneity(featurename1='hsa-miR-21-5p',featurename2='hsa-miR-15b-5p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uca_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convert_label_to_int(sample_class):\n",
    "    classes, counts = np.unique(sample_class, return_counts=True)\n",
    "    classes = np.argmax(sample_class.reshape((-1, 1)) == classes.reshape((1, -1)), axis=1)\n",
    "    return classes\n",
    "\n",
    "def unsupervised_clustering_accuracy(y, y_pred):\n",
    "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "    assert len(y_pred) == len(y)\n",
    "    u = np.unique(np.concatenate((y, y_pred)))\n",
    "    n_clusters = len(u)\n",
    "    mapping = dict(zip(u, range(n_clusters)))\n",
    "    reward_matrix = np.zeros((n_clusters, n_clusters), dtype=np.int64)\n",
    "    for y_pred_, y_ in zip(y_pred, y):\n",
    "        if y_ in mapping:\n",
    "            reward_matrix[mapping[y_pred_], mapping[y_]] += 1\n",
    "    cost_matrix = reward_matrix.max() - reward_matrix\n",
    "    ind = linear_assignment(cost_matrix)\n",
    "    return sum([reward_matrix[i, j] for i, j in ind]) * 1.0 / y_pred.size, ind\n",
    "\n",
    "def uca_scores(X,y, prediction_algorithm='knn'):\n",
    "    from sklearn.metrics import adjusted_rand_score as ARI\n",
    "    from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.mixture import GaussianMixture as GMM\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    cluster_num = np.unique(y).shape[0]\n",
    "    if prediction_algorithm == 'knn':\n",
    "        labels_pred = KMeans(cluster_num, n_init=200).fit_predict(X)  \n",
    "    elif prediction_algorithm == 'gmm':\n",
    "        gmm = GMM(cluster_num)\n",
    "        gmm.fit(X)\n",
    "        labels_pred = gmm.predict(X)\n",
    "    labels = y\n",
    "    #asw_score = silhouette_score(X, labels)\n",
    "    #nmi_score = NMI(labels, labels_pred)\n",
    "    #ari_score = ARI(labels, labels_pred)\n",
    "    labels_int = convert_label_to_int(labels)\n",
    "    uca_score = unsupervised_clustering_accuracy(labels_int, labels_pred)[0]\n",
    "    return uca_score\n",
    "\n",
    "def get_uca_score(data,sampleclass,method_PCA = True,prediction_algorithm='knn'):\n",
    "    X = np.log2(data + 0.001).T\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if method_PCA == True:\n",
    "        transform = PCA()\n",
    "    else:\n",
    "        transform = TSNE()\n",
    "    X_pca = transform.fit_transform(X)\n",
    "    X_, y_ = X_pca, sampleclass.loc[data.columns.values].values.ravel() \n",
    "    #knn_score_ = knn_score(X_, y_)\n",
    "    uca_score = uca_scores(X_, y_, prediction_algorithm)\n",
    "    return uca_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     19
    ]
   },
   "outputs": [],
   "source": [
    "def knn_score(X, y, K=10):\n",
    "    N = X.shape[0]\n",
    "    assert K < N\n",
    "    nn = NearestNeighbors(K)\n",
    "    nn.fit(X)\n",
    "    distances, indices = nn.kneighbors(X, K + 1)\n",
    "    neighbor_classes = np.take(y, indices[:, 1:])\n",
    "    same_class_fractions = np.sum(neighbor_classes == y[:, np.newaxis], axis=1)\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    classes = np.argmax(y.reshape((-1, 1)) == classes.reshape((1, -1)), axis=1)\n",
    "    counts = np.take(counts, classes)\n",
    "    mean_r = K/(N - 1)*counts\n",
    "    max_r = np.minimum(K, counts)\n",
    "    #print (same_class_fractions.shape,mean_r.shape,max_r.shape)\n",
    "    #scores = (np.mean(same_class_fractions) - mean_r)/(max_r - mean_r)\n",
    "    scores = (same_class_fractions - mean_r)/(max_r - mean_r)\n",
    "    #print(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "def get_knn_score(data,sampleclass,method_PCA = True,prediction_algorithm='knn'):\n",
    "    X = np.log2(data + 0.001).T\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if method_PCA == True:\n",
    "        transform = PCA()\n",
    "    else:\n",
    "        transform = TSNE()\n",
    "    X_pca = transform.fit_transform(X)\n",
    "    X_, y_ = X_pca, sampleclass.loc[data.columns.values].values.ravel() \n",
    "    knn_score_ = knn_score(X_, y_)\n",
    "    return knn_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methodlist = []\n",
    "for i in normlist:\n",
    "    for j in batchlist:\n",
    "        methodlist.append(i+'.'+j)\n",
    "methodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_info = pd.read_table('/home/xieyufeng/fig3/data/cfRNA/batch_info.txt',index_col=0)\n",
    "batch_info = pd.read_table('/home/zhaotianxiao/fig3/batch_info.txt', index_col=0)\n",
    "batch_info[batch_info.dataset=='lulab_hcc']='GSE123972'\n",
    "sampleclass = batch_info.iloc[:,0]\n",
    "knn_list=[]\n",
    "for i in tqdm(methodlist):\n",
    "    table = pd.read_table('/home/xieyufeng/fig3/output/'+'cfRNA'+'/matrix_processing/'+i+'.mirna_and_domains.txt',\n",
    "                           index_col=0)\n",
    "    knn_list.append(get_knn_score(table,sampleclass))\n",
    "knn_summary = pd.DataFrame(data={'preprocess_method':methodlist,'knn_score':list(knn_list)})\n",
    "knn_summary = knn_summary.set_index('preprocess_method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = pd.read_table('/home/xieyufeng/fig3/data/cfRNA/sample_classes.txt',index_col=0)\n",
    "sampleclass = class_info\n",
    "uca_list=[]\n",
    "for i in tqdm(methodlist):\n",
    "    table = pd.read_table('/home/xieyufeng/fig3/output/'+'cfRNA'+'/matrix_processing/'+i+'.mirna_and_domains.txt',\n",
    "                           index_col=0)\n",
    "    uca_list.append(get_uca_score(table,sampleclass))\n",
    "uca_summary = pd.DataFrame(data={'preprocess_method':methodlist,'uca_score':list(uca_list)})\n",
    "uca_summary = uca_summary.set_index('preprocess_method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uca_score(table,sampleclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(uca_summary,knn_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([knn_summary,uca_summary],axis=1)\n",
    "merge['impute'] = [method.split('.')[1] for method in merge.index]\n",
    "merge['normalization'] = [method.split('.')[2] for method in merge.index]\n",
    "merge['batch'] = [method.split('.')[3] for method in merge.index]\n",
    "sizelist=[10,50,200]\n",
    "impute_list = np.unique(merge['impute'])\n",
    "merge['imputation_size'] = merge['impute']\n",
    "for i in np.arange(len(impute_list)):\n",
    "    where = np.where(merge['imputation_size']==impute_list[i])\n",
    "    for j in where:\n",
    "        merge['imputation_size'].iloc[j]=sizelist[i]\n",
    "merge.knn_score =1-merge.knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge.drop(merge.iloc[np.where(np.array([i.split('.')[-1] for i in merge.index]) == 'Batch_RUVn_1')[0]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "ax = sns.scatterplot(x='uca_score',y='knn_score',data = merge,hue='batch',style='normalization',\n",
    "                     markers=legendhandle(np.unique(merge.normalization),False,1),\n",
    "                     palette=legendhandle(np.unique(merge.batch),True,1),s=100)\n",
    "#\"PCC score:{:.2f}\".format(pearsonr(uca_summary,knn_summary)[0][0]))\n",
    "\n",
    "h,l=ax.get_legend_handles_labels()\n",
    "l = np.array(l)\n",
    "l[l=='batch']='batch removal method'\n",
    "l[l=='Batch_ComBat_1']='ComBat'\n",
    "l[l=='Batch_null']='null'\n",
    "l[l=='Batch_RUV']='RUV'\n",
    "l[l=='Batch_limma_1']='limma'\n",
    "l[l=='normalization']='normalization method'\n",
    "l[l=='Norm_RLE']='RLE'\n",
    "l[l=='Norm_CPM']='CPM'\n",
    "l[l=='Norm_CPM_top']='CPM-top'\n",
    "l[l=='Norm_TMM']='TMM'\n",
    "l = l.tolist()\n",
    "\n",
    "#ax.legend_.remove()\n",
    "std_plot(ax,'UCA score','mkNN score',h=h,l=l,markerscale=1.5,bbox_to_anchor=(1.05, 0.9))\n",
    "ax.legend_.get_frame()._linewidth=0\n",
    "fig.tight_layout()\n",
    "#fig.savefig(savepath+'uca_knn_binbin_leg.eps')\n",
    "#embed_pdf_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### understand UCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_int(sample_class):\n",
    "    classes, counts = np.unique(sample_class, return_counts=True)\n",
    "    classes = np.argmax(sample_class.reshape((-1, 1)) == classes.reshape((1, -1)), axis=1)\n",
    "    return classes\n",
    "\n",
    "def unsupervised_clustering_accuracy(y, y_pred):\n",
    "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "    assert len(y_pred) == len(y)\n",
    "    u = np.unique(np.concatenate((y, y_pred)))\n",
    "    n_clusters = len(u)\n",
    "    mapping = dict(zip(u, range(n_clusters)))\n",
    "    reward_matrix = np.zeros((n_clusters, n_clusters), dtype=np.int64)\n",
    "    for y_pred_, y_ in zip(y_pred, y):\n",
    "        if y_ in mapping:\n",
    "            reward_matrix[mapping[y_pred_], mapping[y_]] += 1\n",
    "    cost_matrix = reward_matrix.max() - reward_matrix\n",
    "    ind = linear_assignment(cost_matrix)\n",
    "    return sum([reward_matrix[i, j] for i, j in ind]) * 1.0 / y_pred.size, ind\n",
    "\n",
    "def uca_scores(X,y, prediction_algorithm='knn'):\n",
    "    from sklearn.metrics import adjusted_rand_score as ARI\n",
    "    from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.mixture import GaussianMixture as GMM\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    cluster_num = np.unique(y).shape[0]\n",
    "    if prediction_algorithm == 'knn':\n",
    "        labels_pred = KMeans(cluster_num, n_init=200).fit_predict(X) \n",
    "        print(labels_pred)\n",
    "        print(np.unique(labels_pred,return_counts=True))\n",
    "    elif prediction_algorithm == 'gmm':\n",
    "        gmm = GMM(cluster_num)\n",
    "        gmm.fit(X)\n",
    "        labels_pred = gmm.predict(X)\n",
    "    labels = y\n",
    "    #asw_score = silhouette_score(X, labels)\n",
    "    #nmi_score = NMI(labels, labels_pred)\n",
    "    #ari_score = ARI(labels, labels_pred)\n",
    "    labels_int = convert_label_to_int(labels)\n",
    "    uca_score = unsupervised_clustering_accuracy(labels_int, labels_pred)[0]\n",
    "    return uca_score,unsupervised_clustering_accuracy(labels_int, labels_pred)[1]\n",
    "\n",
    "def get_uca_score(data,sampleclass,method_PCA = True,prediction_algorithm='knn'):\n",
    "    X = np.log2(data + 0.001).T\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if method_PCA == True:\n",
    "        transform = PCA()\n",
    "    else:\n",
    "        transform = TSNE()\n",
    "    X_pca = transform.fit_transform(X)\n",
    "    X_, y_ = X_pca, sampleclass.loc[data.columns.values].values.ravel() \n",
    "    #knn_score_ = knn_score(X_, y_)\n",
    "    uca_score,ind = uca_scores(X_, y_, prediction_algorithm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_uca_score(table,sampleclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sampleclass.loc[table.columns.values].values.ravel() \n",
    "print(convert_label_to_int(labels))\n",
    "print(np.unique(convert_label_to_int(labels),return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uca_scores(X,y, prediction_algorithm='knn'):\n",
    "    from sklearn.metrics import adjusted_rand_score as ARI\n",
    "    from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.mixture import GaussianMixture as GMM\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    cluster_num = np.unique(y).shape[0]\n",
    "    if prediction_algorithm == 'knn':\n",
    "        labels_pred = KMeans(cluster_num, n_init=200).fit_predict(X) \n",
    "    elif prediction_algorithm == 'gmm':\n",
    "        gmm = GMM(cluster_num)\n",
    "        gmm.fit(X)\n",
    "        labels_pred = gmm.predict(X)\n",
    "    labels = y\n",
    "    #asw_score = silhouette_score(X, labels)\n",
    "    #nmi_score = NMI(labels, labels_pred)\n",
    "    #ari_score = ARI(labels, labels_pred)\n",
    "    labels_int = convert_label_to_int(labels)\n",
    "    uca_score = unsupervised_clustering_accuracy(labels_int, labels_pred)[0]\n",
    "    return uca_score,unsupervised_clustering_accuracy(labels_int, labels_pred)[1]\n",
    "def get_uca_score(data,sampleclass,method_PCA = True,prediction_algorithm='knn'):\n",
    "    X = np.log2(data + 0.001).T\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if method_PCA == True:\n",
    "        transform = PCA()\n",
    "    else:\n",
    "        transform = TSNE()\n",
    "    X_pca = transform.fit_transform(X)\n",
    "    X_, y_ = X_pca, sampleclass.loc[data.columns.values].values.ravel() \n",
    "    #knn_score_ = knn_score(X_, y_)\n",
    "    uca_score,ind = uca_scores(X_, y_, prediction_algorithm)\n",
    "    return ind\n",
    "get_uca_score(table,sampleclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### understand mkNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first alignment score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\text{Alignment\\ Score} = \\frac{1}{k-\\frac{k}{N}}(k-\\overline{x})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$k$是最近邻算法（k nearest-neighbors, kNN）的前$k$个最近邻，$\\overline{x}$是样本周围的样本同属一个批次的数量的平均，$N$表示样本数。\n",
    "当两个批次样本完全分开时，$k=\\overline{x}$，$\\text{Alignment\\ Score}=0$；当两个批次样本完全混杂时，比例因子$\\frac{1}{k-\\frac{k}{N}}$作用下，$\\text{Alignment\\ Score}$接近1。\n",
    "\\pkg{exSeek}提出了适用于多种批次的mkNN指标\\footnote{该指标由由史斌斌（\\url{ltbyshi@gmail.com}）首次提出}。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mkNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\text{Alignment\\ Score} = 1-\\frac{\\overline{x}-\\frac{k}{N}}{k-\\frac{k}{N}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\text{mkNN}=1-\\frac{1}{B} \\sum_{b=1}^{B} \\frac{\\overline{x}_{b}-k N_{b} /(N-1)}{\\min \\left(k, N_{b}\\right)-k N_{b} /(N-1)}\n",
    "\\end{equation}\n",
    "其中，$b$表示批次，$B$为批次数量，$N_b$是批次$b$下样本的数量。批次效应越明显，该指标越接近0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('https://drive.google.com/file/d/1yWvw3fwWeSSrBgmhz_uaC4oQ0wltkIge/preview',\n",
    "      width=800,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_plot_with_uca_score_sns(ax,data,sampleclass,batchinfo, method = 'PCA'):\n",
    "    X = log_transform(data).T\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if method == 'PCA':\n",
    "        transform = PCA()\n",
    "    elif method == 'tSNE':\n",
    "        transform = TSNE()\n",
    "    elif method == 'UMAP':\n",
    "        transform = umap.UMAP(n_neighbors=5,min_dist=0.3,metric='correlation')\n",
    "    \n",
    "    X_pca = transform.fit_transform(X)\n",
    "    plot_table = pd.DataFrame(X_pca[:,:2])\n",
    "    plot_table.index = data.columns\n",
    "    plot_table = pd.concat((plot_table,sampleclass.loc[plot_table.index],batchinfo.loc[plot_table.index]),axis=1)\n",
    "    plot_table.columns = ['Dimension 1','Dimension 2','class','batch']\n",
    "    plot_table = plot_table.sort_values(by='batch')\n",
    "    classnum = np.unique(plot_table.iloc[:,2]).shape[0]\n",
    "    sns.scatterplot(ax=ax,data=plot_table,x=\"Dimension 1\", y=\"Dimension 2\",\n",
    "                    palette=legendhandle(np.unique(plot_table.batch)) , hue=\"batch\",style='class',s=50,linewidth=0.01)\n",
    "    \n",
    "    #plt.figure(linewidth=30.5)\n",
    "\n",
    "        #legend.get_title().set_fontweight('normal')\n",
    "        #legend.get_title().set_fontsize(6.5)\n",
    "    #ax.legend(bbox_to_anchor = (1, 1))\n",
    "    #ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #uca_score = get_clustering_score(data, sampleclass)\n",
    "    #ax.set_title(method_type + ': ' +'UCA = {:.3f}'.format(uca_score) +', ' + 'kBET = {:.3f}'.format(kbet_score))\n",
    "    #ax.annotate('UCA score: {:.6f}'.format(uca_score),xy=(1,0),xycoords='data',size=6.5)\n",
    "    #print('Alignment score: {}'.format(knn_score(X_pca, sampleclass.loc[data.columns.values].values.ravel() )))\n",
    "\n",
    "\n",
    "def log_transform(data, small = 0.01):\n",
    "    return np.log2(data + small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 6.5\n",
    "fontscale = 1\n",
    "fontweight =  'normal'\n",
    "fonttitle = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "                  'size' : fontsize*fontscale}\n",
    "fontlabel = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "                  'size' : fontsize*fontscale}\n",
    "fontticklabel = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "                  'size' : fontsize*fontscale}\n",
    "fontlegend = {'family':'Arial',\n",
    "                  'weight' : fontweight, \n",
    "              #'linewidth':0.5,\n",
    "                  'size' : fontsize*fontscale}\n",
    "fontcbarlabel = {'family':'Arial',\n",
    "                 'weight' : fontweight, \n",
    "                 #'Rotation' : 270,\n",
    "                 #'labelpad' : 25,\n",
    "                 'size' : fontsize*fontscale}\n",
    "fontcbarticklabel = {'family':'Arial',#Helvetica\n",
    "                 'weight' : fontweight, \n",
    "                 'size' : (fontsize-1)*fontscale}\n",
    "\n",
    "def std_plot(ax,xlabel=None,ylabel=None,title=None,\n",
    "             legendtitle=None,bbox_to_anchor=None,\n",
    "             labelspacing=0.2,borderpad=0.2,handletextpad=0.2,legendsort=False,markerscale=None,\n",
    "             xlim=None,ylim=None,\n",
    "             xbins=None,ybins=None,\n",
    "             cbar=None,cbarlabel=None,\n",
    "             moveyaxis=False,sns=False,left=True,rotation=None,xticklabel=None,legendscale=True,h=None,l=None,**kwards):\n",
    "        # height = 2 font = 6.5\n",
    "    def autoscale(fig):\n",
    "        if isinstance(fig,matplotlib.figure.Figure):\n",
    "            width,height = fig.get_size_inches()\n",
    "        elif isinstance(fig,matplotlib.axes.Axes):\n",
    "            width,height = fig.figure.get_size_inches()\n",
    "        fontscale = height/3\n",
    "        if width/fontscale > 8:\n",
    "            warnings.warn(\"Please reset fig's width. When scaling the height to 2 in, the scaled width '%.2f' is large than 8\"%(width/fontscale),UserWarning)\n",
    "        return fontscale\n",
    "    \n",
    "    class fontprop:\n",
    "        def init(self,fonttitle=None,fontlabel=None,fontticklabel=None,fontlegend=None,fontcbarlabel=None,fontcbarticklabel=None):\n",
    "            self.fonttitle = fonttitle\n",
    "            self.fontlabel = fontlabel\n",
    "            self.fontticklabel = fontticklabel\n",
    "            self.fontlegend = fontlegend\n",
    "            self.fontcbarlabel = fontcbarlabel\n",
    "            self.fontcbarticklabel = fontcbarticklabel\n",
    "        def update(self,fontscale):\n",
    "            self.fonttitle['size'] = self.fonttitle['size']*fontscale\n",
    "            self.fontlabel['size'] = self.fontlabel['size']*fontscale\n",
    "            self.fontticklabel['size'] = self.fontticklabel['size']*fontscale\n",
    "            self.fontlegend['size'] = self.fontlegend['size']*fontscale\n",
    "            self.fontcbarlabel['size'] = self.fontcbarlabel['size']*fontscale\n",
    "            self.fontcbarticklabel['size'] = self.fontcbarticklabel['size']*fontscale\n",
    "        def reset(self,fontscale):\n",
    "            self.fonttitle['size'] = self.fonttitle['size']/fontscale\n",
    "            self.fontlabel['size'] = self.fontlabel['size']/fontscale\n",
    "            self.fontticklabel['size'] = self.fontticklabel['size']/fontscale\n",
    "            self.fontlegend['size'] = self.fontlegend['size']/fontscale\n",
    "            self.fontcbarlabel['size'] = self.fontcbarlabel['size']/fontscale\n",
    "            self.fontcbarticklabel['size'] = self.fontcbarticklabel['size']/fontscale\n",
    "    fontscale = autoscale(ax)\n",
    "    font = fontprop()\n",
    "    font.init(fonttitle,fontlabel,fontticklabel,fontlegend,fontcbarlabel,fontcbarticklabel)\n",
    "    font.update(fontscale)\n",
    "    \n",
    "    pyplot.draw()\n",
    "    #plt.figure(linewidth=30.5)\n",
    "    if xlim is not None:  \n",
    "        ax.set(xlim=xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set(ylim=ylim)\n",
    "    #pyplot.draw()\n",
    "    if xbins is not None:\n",
    "        locator = MaxNLocator(nbins=xbins)\n",
    "        locator.set_axis(ax.xaxis)\n",
    "        ax.set_xticks(locator())\n",
    "    if ybins is not None:\n",
    "        locator = MaxNLocator(nbins=ybins)\n",
    "        locator.set_axis(ax.yaxis)\n",
    "        ax.set_yticks(locator())\n",
    "    pyplot.draw()\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_xlabel(xlabel,fontdict = font.fontlabel,labelpad=(fontsize-1)*fontscale)\n",
    "    ax.set_ylabel(ylabel,fontdict = font.fontlabel,labelpad=(fontsize-1)*fontscale)\n",
    "    if (rotation is not None) & (xticklabel is not None) :\n",
    "        ax.set_xticklabels(xticklabel,fontticklabel,rotation=rotation)\n",
    "    elif (xticklabel is not None) &(rotation is None):\n",
    "        ax.set_xticklabels(xticklabel,fontticklabel)\n",
    "    elif (xticklabel is None) &(rotation is None):\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),fontticklabel)\n",
    "    elif (rotation is not None) & (xticklabel is None):\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),fontticklabel,rotation=rotation)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(),font.fontticklabel)\n",
    "\n",
    "    if moveyaxis is True:\n",
    "        #fontticklabel \n",
    "        ax.spines['left'].set_position(('data',0))\n",
    "    ax.spines['left'].set_visible(left)\n",
    "    ax.spines['right'].set_visible(not left)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_linewidth(0.5*fontscale)\n",
    "    ax.spines['bottom'].set_linewidth(0.5*fontscale)\n",
    "    ax.spines['left'].set_linewidth(0.5*fontscale)\n",
    "    ax.spines['bottom'].set_color('k')\n",
    "    ax.spines['left'].set_color('k')\n",
    "    ax.spines['right'].set_color('k')\n",
    "    \n",
    "    ax.tick_params(direction='out', pad=2*fontscale,width=0.5*fontscale)\n",
    "    #ax.spines['bottom']._edgecolor=\"#000000\"\n",
    "    #ax.spines['left']._edgecolor=\"#000000\"\n",
    "    if title is not None:\n",
    "        ax.set_title(title,fontdict = font.fonttitle)\n",
    "    if legendscale is True:\n",
    "        if (h is None)&(l is None):\n",
    "            legend = ax.legend(prop=font.fontlegend,\n",
    "                  bbox_to_anchor=bbox_to_anchor,\n",
    "                  labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "        else:\n",
    "            legend = ax.legend(h,l,prop=font.fontlegend,\n",
    "                  bbox_to_anchor=bbox_to_anchor,\n",
    "                  labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                  edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "    if legendtitle is not None:\n",
    "        #if legendloc is None:\n",
    "        #    legendloc=\"best\"\n",
    "        legend = ax.legend(title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "        ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "        legend.get_title().set_fontweight('normal')\n",
    "        legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "        if legendsort is True:\n",
    "            # h: handle l:label\n",
    "            h,l = ax.get_legend_handles_labels()\n",
    "            l,h = zip(*sorted(zip(l,h), key=lambda t: int(t[0]))) \n",
    "            legend = ax.legend(h,l,title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "            ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "            legend.get_title().set_fontweight('normal')\n",
    "            legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "        if sns is True:\n",
    "            h,l = ax.get_legend_handles_labels()\n",
    "            #l,h = zip(*sorted(zip(l,h), key=lambda t: int(t[0]))) \n",
    "            legend = ax.legend(h[1:],l[1:],title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "            ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "            legend.get_title().set_fontweight('normal')\n",
    "            legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "    else:\n",
    "        legend = ax.legend(handles=h,labels=l,title=legendtitle,prop=font.fontlegend,\n",
    "                      bbox_to_anchor=bbox_to_anchor,\n",
    "                      labelspacing=labelspacing,borderpad=borderpad,handletextpad=handletextpad,\n",
    "                      edgecolor=\"#000000\",fancybox=False,markerscale=markerscale,**kwards)\n",
    "        ax.legend_.get_frame()._linewidth=0.5*fontscale\n",
    "        legend.get_title().set_fontweight('normal')\n",
    "        legend.get_title().set_fontsize(fontscale*fontsize)\n",
    "\n",
    "    if cbar is not None:\n",
    "        #locator, formatter = cbar._get_ticker_locator_formatter()\n",
    "        #ticks, ticklabels, offset_string = cbar._ticker(locator, formatter)\n",
    "        #cbar.ax.spines['top'].set_visible(False)\n",
    "        #cbar.ax.spines['right'].set_visible(False)\n",
    "        #cbar.ax.spines['bottom'].set_visible(False)\n",
    "        #cbar.ax.spines['left'].set_visible(False)\n",
    "        cbar.ax.tick_params(direction='out', pad=3*fontscale,width=0*fontscale,length=0*fontscale)\n",
    "        cbar.set_label(cbarlabel,fontdict = font.fontcbarlabel,Rotation=270,labelpad=fontscale*(fontsize+1))\n",
    "        cbar.ax.set_yticks(cbar.ax.get_yticks())\n",
    "        cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(),font.fontcbarticklabel)\n",
    "    font.reset(fontscale)\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_class = pd.read_table('/home/xieyufeng/fig3/data/cfRNA/sample_classes.txt', index_col=0)\n",
    "batch_info = pd.read_table('/home/xieyufeng/fig3/data/cfRNA/batch_info.txt', index_col=0)\n",
    "batch_info[batch_info.dataset=='lulab_hcc']='GSE123972'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_class[sample_class.label=='Normal']='HD'\n",
    "sample_class[sample_class.label!='HD']='HCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_info = pd.read_table('/home/zhaotianxiao/fig3/batch_info.txt', index_col=0)\n",
    "batch_info[batch_info.dataset=='lulab_hcc']='GSE123972'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbet_table = pd.read_table('/home/xieyufeng/fig3/output/cfRNA/select_preprocess_method/kbet_score/mirna_and_domains/summary.txt', index_col = 0)\n",
    "uca_table = pd.read_table('/home/xieyufeng/fig3/output/cfRNA/select_preprocess_method/uca_score/mirna_and_domains/summary.txt', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbet_table = pd.read_table('/home/shibinbin/projects/exSeek-dev/output/cfRNA/select_preprocess_method/kbet_score/mirna_and_domains/summary.txt', index_col = 0)\n",
    "uca_table = pd.read_table('/home/shibinbin/projects/exSeek-dev/output/cfRNA/select_preprocess_method/uca_score/mirna_and_domains/summary.txt', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_summary = pd.read_csv('/home/shibinbin/projects/exSeek-dev/output/cfRNA/select_preprocess_method/knn_score/mirna_and_domains/summary.txt',sep='\\t')\n",
    "knn_summary = knn_summary.set_index('preprocess_method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'filter.null.Norm_RLE.Batch_limma_1'\n",
    "data = pd.read_table('/home/xieyufeng/fig3/output/cfRNA/matrix_processing/'+method+'.mirna_and_domains.txt',\n",
    "                          index_col = 0)\n",
    "fig, (ax,lax) = plt.subplots(ncols=2, gridspec_kw={\"width_ratios\":[4,1]},figsize=(8.5,6))\n",
    "PCA_plot_with_uca_score_sns(ax,data,sample_class, batch_info,method='PCA')\n",
    "\n",
    "h,l=ax.get_legend_handles_labels()\n",
    "for loc in range(len(l)):\n",
    "    if l[loc] == 'GSE94582_NEBNext':\n",
    "        l[loc] = 'GSE94582_1'\n",
    "    elif l[loc] == 'GSE94582_Other':\n",
    "        l[loc] = 'GSE94582_2'\n",
    "    elif l[loc] == 'GSE94582_TruSeq':\n",
    "        l[loc] = 'GSE94582_3'\n",
    "        \n",
    "std_plot(ax,'Dimension 1','Dimension 2',\n",
    "             title='RLE with Limma',\n",
    "             xbins=4,ybins=5,h=h,l=l,bbox_to_anchor=(0.9,0.8),markerscale=1.5)\n",
    "ax.legend_.remove()\n",
    "lax.axis(\"off\")\n",
    "std_plot(lax,h=h,l=l,bbox_to_anchor=(1,0.8),markerscale=2,labelspacing=0.3)\n",
    "lax.legend_.get_frame()._linewidth=0\n",
    "fig.tight_layout()\n",
    "#fig.savefig(savepath+'RLE with Limma.eps')\n",
    "#embed_pdf_figure()\n",
    "print('UCA = {:.3f}'.format(uca_summary.loc[method].values[0]) +', ' + 'mkNN = {:.3f}'.format(1-knn_summary.loc[method].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'filter.null.Norm_RLE.Batch_null'\n",
    "data = pd.read_table('/home/xieyufeng/fig3/output/cfRNA/matrix_processing/'+method+'.mirna_and_domains.txt',\n",
    "                          index_col = 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.1,6))\n",
    "PCA_plot_with_uca_score_sns(ax,data,sample_class, batch_info,method='PCA')\n",
    "std_plot(ax,'Dimension 1','Dimension 2',title='RLE',xbins=4,ybins=5)\n",
    "\n",
    "ax.legend_.remove()\n",
    "fig.tight_layout()\n",
    "#fig.savefig(savepath+'RLE with Null_noleg.eps')\n",
    "#embed_pdf_figure()\n",
    "method = 'filter.null.Norm_RLE.Batch_null'\n",
    "#print('UCA = {:.3f}'.format(uca_summary.loc[method].values[0]) +', ' + 'mkNN = {:.3f}'.format(1-knn_summary.loc[method].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_ex(mat,anno_info):\n",
    "    from scipy.stats import f\n",
    "    def list201(array):\n",
    "        dataframe = pd.DataFrame()\n",
    "        for i in np.unique(array):\n",
    "            dataframe[i] = array==i\n",
    "        return dataframe\n",
    "\n",
    "    rsquared_mat = pd.DataFrame()\n",
    "    bms = pd.DataFrame()\n",
    "    wms = pd.DataFrame()\n",
    "    fvalue = pd.DataFrame()\n",
    "    p = pd.DataFrame()\n",
    "    rsquared_cutoff=pd.DataFrame()\n",
    "    tss_all = (np.var(mat.T)*mat.shape[1]).tolist()\n",
    "    var_list = anno_info.columns\n",
    "    for var in var_list:\n",
    "        anno = anno_info[var]\n",
    "        if len(np.unique(anno))<=1:\n",
    "            warnings.warn(\"ignoring '%s' with fewer than 2 unique levels\"%var,UserWarning)\n",
    "        keep = ~anno.isna()\n",
    "        if np.all(keep):\n",
    "            tss = tss_all\n",
    "        else:\n",
    "            anno = anno[keep]\n",
    "            mat = mat.loc[:,keep]\n",
    "            tss = np.array(np.var(mat.T)*mat.shape[1])\n",
    "        anno2class = list201(anno)\n",
    "        wss = 0\n",
    "        for i in anno2class.columns:\n",
    "            mat_select=mat.iloc[:,np.where(anno2class[i])[0]]\n",
    "            wss = wss + np.array(np.var(mat_select.T)*mat_select.shape[1])\n",
    "        #display(wss)\n",
    "        rsquared_mat[var] = 1-wss/tss\n",
    "        bms[var] = (tss-wss)/(anno2class.shape[1]-1)\n",
    "        wms[var] = wss/(len(anno)-anno2class.shape[1])\n",
    "        fvalue[var] = bms[var]/wms[var]\n",
    "        p[var] = [1-f.cdf(i,anno2class.shape[1]-1,len(anno)-anno2class.shape[1]) for i in fvalue[var]]\n",
    "        rsquared_cutoff[var] = [1-1/(f.isf(0.05, anno2class.shape[1]-1, len(anno)-anno2class.shape[1])*\\\n",
    "                               (anno2class.shape[1]-1)/(len(anno)-anno2class.shape[1])+1)]\n",
    "    return rsquared_mat,rsquared_cutoff,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchinfo_path =\"/home/xieyufeng/fig3/data/cfRNA/batch_info.txt\"\n",
    "batchinfo_path =\"/home/xieyufeng/fig3/data/cfRNA/batch_info.txt\"\n",
    "classinfo_path = \"/home/xieyufeng/fig3/data/cfRNA/sample_classes.txt\"\n",
    "mat1_path=\"/home/xieyufeng/fig3/output/cfRNA/matrix_processing/filter.null.Norm_RLE.Batch_null.mirna_and_domains.txt\"\n",
    "mat2_path=\"/home/xieyufeng/fig3/output/cfRNA/matrix_processing/filter.null.Norm_RLE.Batch_limma_1.mirna_and_domains.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = pd.read_csv(mat1_path,sep='\\t')\n",
    "mat2 = pd.read_csv(mat2_path,sep='\\t')\n",
    "batch_info = pd.read_csv(batchinfo_path,sep='\\t')\n",
    "batch_info = pd.read_table('/home/zhaotianxiao/fig3/batch_info.txt')\n",
    "sample_info = pd.read_csv(classinfo_path,sep='\\t')\n",
    "anno_info = pd.merge(batch_info,sample_info,on=['sample_id'])\n",
    "anno_info = anno_info.set_index('sample_id')\n",
    "anno_info = anno_info.loc[mat1.columns]\n",
    "#anno_info = anno_info.reset_index()\n",
    "rsquared_mat1,rsquared_cutoff1,p1 = var_ex(mat1,anno_info)\n",
    "anno_info = anno_info.loc[mat2.columns]\n",
    "rsquared_mat2,rsquared_cutoff2,p2 = var_ex(mat2,anno_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "def r2mat21class(rsquared_mat1=None,rsquared_mat2=None,rsquared_cutoff=rsquared_cutoff1,p1=None,p2=None):\n",
    "    fig =plt.figure(figsize=(6,4))\n",
    "    gs = gridspec.GridSpec(2, rsquared_mat1.shape[1],height_ratios=[4,1])\n",
    "    #fig,(axes,lax)=plt.subplots(2,rsquared_mat1.shape[1],gridspec_kw={\"height_ratios\":[4,1]},figsize=(6,4))\n",
    "    lax = fig.add_subplot(gs[1, :])\n",
    "    pyplot.draw()\n",
    "    for i in range(len(rsquared_mat1.columns)):\n",
    "        axes = fig.add_subplot(gs[0, i])\n",
    "        var = rsquared_mat1.columns[i]\n",
    "        plot_mat = pd.DataFrame([rsquared_mat1[var],rsquared_mat2[var]]).T\n",
    "        plot_mat.columns=['before batch removal','after batch removal']\n",
    "        cutoff = rsquared_cutoff[var].iloc[0]\n",
    "        #axes[i].set_xscale('log',subsx=[-2,-1,0,1,2])\n",
    "        #axes[i].hist(plot_mat.before,500,density=1)\n",
    "        sns.kdeplot(plot_mat['before batch removal'],ax=axes,c='#80b1d3')#,bw=0.001,kernel='gau')\n",
    "        sns.kdeplot(plot_mat['after batch removal'],ax=axes,c='#fb8072')#,bw=0.001)\n",
    "        axes.axvline(x=cutoff,linestyle='--',linewidth=0.5,c='k')\n",
    "        axes.set_xticks([-2,-1,0,1,2])#,cutoff])\n",
    "        axes.set_xticklabels([0.01,0.1,1,10,100])#,'%.1f'%math.pow(10,cutoff)])\n",
    "        ymax,ymin = max(axes.get_yticks()),min(axes.get_yticks())\n",
    "        axes.annotate('%.2f'%math.pow(10,cutoff),xy=(cutoff+0.1,0.05*ymin+0.95*ymax),fontfamily='Arial',fontsize=6.5*autoscale(fig))\n",
    "        axes.legend(title='state',prop=fontlegend)\n",
    "        if i==0:\n",
    "            if var=='dataset':\n",
    "                std_plot(axes,'Variance explained%','Density',legendtitle='state',legendsort=False,title='Batches',xlim=[-2,2],bbox_to_anchor=(1, 0.75))\n",
    "            elif var=='label':\n",
    "                std_plot(axes,'Variance explained%','Density',legendtitle='state',legendsort=False,title='Cancer/Normal',xlim=[-2,2],bbox_to_anchor=(1, 0.75))\n",
    "        else:\n",
    "            if var=='dataset':\n",
    "                std_plot(axes,'Variance explained%','',legendtitle='state',legendsort=False,title='Batches',xlim=[-2,2],bbox_to_anchor=(1,-0.2))\n",
    "            elif var=='label':  \n",
    "                std_plot(axes,'Variance explained%','',legendtitle='state',legendsort=False,title='Cancer/Normal',xlim=[-2,2],bbox_to_anchor=(1,-0.3),ncol=2)\n",
    "        axes.legend_.get_frame()._linewidth=0\n",
    "        #axes[i].legend(title='s',prop=fontlegend)\n",
    "        \n",
    "        p_mat = pd.DataFrame([p1[var],p2[var]]).T\n",
    "        p_mat.columns=['before','after']\n",
    "        #display(p_mat)\n",
    "        #table = axes[i].table(cellText=np.array([np.int_(np.sum(p_mat<0.05)),\n",
    "        #                           ['%.2f'%i for i in (np.sum(p_mat<0.05)/len(p_mat))]]),\n",
    "        #         colLabels=['before','after'],rowLabels=['amount','percentage'],\n",
    "        #                      colWidths=[0.3,0.3],\n",
    "        #                      bbox=[0,0,0.5,0.35])\n",
    "        #table.set_fontsize(6.5)\n",
    "        if i != len(rsquared_mat1.columns)-1:\n",
    "            axes.legend_.remove()\n",
    "        #plt.subplots_adjust(left=0.4, bottom=0.4)\n",
    "    #axes[-1].axis('off')\n",
    "    lax.axis(\"off\")\n",
    "    h,l=axes.get_legend_handles_labels()\n",
    "    axes.legend_.remove()\n",
    "    std_plot(lax,h=h,l=l,bbox_to_anchor=(1,1),markerscale=2,labelspacing=0.3,ncol=2)\n",
    "    fig.tight_layout() \n",
    "    #fig.savefig(savepath+'variance_explained.eps')\n",
    "       \n",
    "    #embed_pdf_figure()\n",
    "r2mat21class(np.log10(rsquared_mat1*100),np.log10(rsquared_mat2*100),np.log10(rsquared_cutoff1*100),p1,p2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mat = pd.DataFrame([p1.label,p2.label]).T\n",
    "p_mat.columns=['before','after']\n",
    "np.sum(p_mat<0.01)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
